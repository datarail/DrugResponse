{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d80a8b4-f825-4395-9121-80081b942bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import math\n",
    "\n",
    "from cell_cycle_gating import manual_gating as mg\n",
    "from cell_cycle_gating import dead_cell_filter_ldrint as dcf_int\n",
    "\n",
    "import patchworklib as pw\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from cell_cycle_gating import findpeaks as fp\n",
    "from pomegranate.gmm import GeneralMixtureModel\n",
    "from pomegranate.distributions import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6eb684-91f5-440b-9613-542a0d7fa508",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the names of wells, valid wells (excluding outer two rows/columns), etc.\n",
    "## input:\n",
    "##    var: either \"all_wells\", \"valid_wells\", \"all_well_rows\", or \"all_well_cols\"\n",
    "## output: a list with the corresponding info, e.g. [\"A01\", \"A02\", ... , \"P24\"] for all_wells\n",
    "def get_well_names(var):\n",
    "    all_well_rows = string.ascii_uppercase[0:16]\n",
    "    all_well_cols = [str(num).zfill(2) for num in range(1,25)]\n",
    "    valid_well_rows = all_well_rows[2:14]\n",
    "    valid_well_cols = all_well_cols[2:22]\n",
    "    ### get all wells\n",
    "    all_wells = [row + col for row in all_well_rows for col in all_well_cols]\n",
    "    all_wells.sort()\n",
    "    ### get valid wells\n",
    "    valid_wells = [row + col for row in valid_well_rows for col in valid_well_cols]\n",
    "    valid_wells.sort()\n",
    "    out = {\n",
    "        'all_wells':all_wells,\n",
    "        'valid_wells':valid_wells,\n",
    "        'all_well_rows':all_well_rows,\n",
    "        'all_well_cols':all_well_cols,\n",
    "        'valid_well_rows':valid_well_rows,\n",
    "        'valid_well_cols':valid_well_cols\n",
    "    }\n",
    "    return(out[var])\n",
    "\n",
    "## Define a dictionary with the local folder name for experiments on each date\n",
    "def define_folder_dict(name='folder_dict'):\n",
    "    folder_dict = {\n",
    "            '2020-11-17':'rep3',\n",
    "            '2021-02-19':'rep4',\n",
    "            '2021-02-26':'rep5',\n",
    "            '2021-03-02':'rep6',\n",
    "            '2021-04-06':'rep7',\n",
    "            '2021-04-23':'rep8',\n",
    "            '2021-05-18':'rep9',\n",
    "            '2021-05-21':'rep10',\n",
    "            '2021-06-11':'rep11',\n",
    "            '2021-07-27':'2_rep1/210727-combo-rep1',\n",
    "            '2021-07-30':'2_rep2/210730_combo_rep2',\n",
    "            '2021-08-06':'2_rep3/210806_combo_rep3',\n",
    "            '2021-10-05':'redo_rep1_and_2',\n",
    "            '2021-10-15':'redo_rep1_and_2/redo_rep2',\n",
    "            '2021-10-29':'redo_rep3'\n",
    "        }\n",
    "    globals()[name] = folder_dict\n",
    "    return(None)\n",
    "\n",
    "def get_base_dir():\n",
    "    ### note: using linux/unix folder conventions -- would need to re-write for Windows\n",
    "    base_dir = \"/mnt/y/lsp-analysis/LINCS-combinations\"\n",
    "    if os.path.exists(base_dir):\n",
    "        return(base_dir)\n",
    "    elif os.path.exists(\"/Volumes/hits/lsp-analysis/LINCS-combinations\"):\n",
    "        return(\"/Volumes/hits/lsp-analysis/LINCS-combinations\")\n",
    "    else:\n",
    "        raise Exception(\"Base directory not found -- need to mount research.files and supply its path, e.g. '/mnt/y/lsp-analysis/LINCS-combinations'\")\n",
    "\n",
    "def get_plates_to_regate():\n",
    "    base_dir = get_base_dir()\n",
    "    ### time_zero plates\n",
    "    time_zero_file = os.path.join(base_dir, \"re_gating\", \"plates_to_regate\", \"time_zero_regate_plates.csv\")\n",
    "    well_file = os.path.join(base_dir, \"re_gating\", \"plates_to_regate\", \"time_zero_regate_wells.csv\")\n",
    "    df_plates1 = pd.read_csv(time_zero_file)\n",
    "    df_wells1 = pd.read_csv(well_file)\n",
    "    df_wells1['time'] = \"time_zero\"\n",
    "    df_plates1['time'] = \"time_zero\"\n",
    "    ### end-time control plates\n",
    "    ctrl_end_file = os.path.join(base_dir, \"re_gating\", \"plates_to_regate\", \"ctrl_end_time_regate_plates.csv\")\n",
    "    well_file = os.path.join(base_dir, \"re_gating\", \"plates_to_regate\", \"ctrl_end_time_regate_wells.csv\")\n",
    "    df_plates2 = pd.read_csv(ctrl_end_file)\n",
    "    df_wells2 = pd.read_csv(well_file)\n",
    "    df_wells2['time'] = \"end_time_control\"\n",
    "    df_plates2['time'] = \"end_time_control\"\n",
    "    ### combine data frames\n",
    "    df_plates = pd.concat([df_plates1, df_plates2])\n",
    "    df_wells = pd.concat([df_wells1, df_wells2])\n",
    "    return(df_plates, df_wells)\n",
    "\n",
    "## Get a list of plate barcodes for a given date\n",
    "## input:\n",
    "##    date: e.g. '2021-10-15'\n",
    "## output: list of barcodes e.g. '211015_combo_173'\n",
    "def get_barcodes(date):\n",
    "    date_formatted = date_format_switch(date)\n",
    "    main_dir = get_data_dir(date = date)\n",
    "    dirs = [ x for x in os.listdir(main_dir) if os.path.isdir( os.path.join(main_dir, x) )]\n",
    "    ### match date at the start of the sub-directory\n",
    "    dirs_barcodes = [ x for x in dirs if bool(re.match(date_formatted+\"_combo\", x)) ]\n",
    "    return( dirs_barcodes )\n",
    "\n",
    "## Switch the format of a date from YYYY-MM-DD to YYMMDD\n",
    "## input:\n",
    "##    date: e.g. '2021-02-19'\n",
    "## output: e.g. '210219'\n",
    "def date_format_switch(date):\n",
    "    new_str = date[2:4] + date[5:7] + date[8:10]\n",
    "    return(new_str)\n",
    "\n",
    "## Get the date in YYYY-MM-DD format from a plate barcode\n",
    "## input:\n",
    "##    barcode: '210406_combo_71'\n",
    "## output: e.g. '2021-04-06'\n",
    "def date_from_barcode(barcode):\n",
    "    date = '20' + barcode[0:2] + '-' + barcode[2:4] + '-' + barcode[4:6]\n",
    "    return(date)\n",
    "\n",
    "## Get the well-level data directory for a given date or barcode\n",
    "## input:\n",
    "##    barcode: a plate barcode, e.g. '210406_combo_71'\n",
    "##    date: a date in YYYY-MM-DD format, e.g. '2021-04-06'\n",
    "##    base_dir: the full path of the data folder, e.g. \"/mnt/y/lsp-analysis/LINCS-combinations/\"\n",
    "## output:\n",
    "##    returns the directory of the well-level data for a barcode\n",
    "##    if a date is given and no barcode, returns the directory of all data for the date\n",
    "##    if no date or barcode is given, returns the base directory of all data\n",
    "def get_data_dir(barcode=None, date=None, base_dir = \"/mnt/y/lsp-analysis/LINCS-combinations/\"):\n",
    "    ### note: using unix folder conventions -- would need to re-write for Windows\n",
    "    ### set for osx\n",
    "    if not os.path.exists(base_dir):\n",
    "        base_dir = \"/Volumes/hits/lsp-analysis/LINCS-combinations/\"\n",
    "    if barcode is None and date is None:\n",
    "        return(base_dir)\n",
    "    if date is None:\n",
    "        date = date_from_barcode(barcode)\n",
    "    if barcode is None:\n",
    "        plate_dir = ''\n",
    "    else:\n",
    "        plate_dir = barcode\n",
    "    #folder_dict = define_folder_dict()\n",
    "    if not 'folder_dict' in globals(): define_folder_dict('folder_dict')\n",
    "    local_dir = folder_dict[date]\n",
    "    full_dir = os.path.join(base_dir, local_dir, plate_dir)\n",
    "    return(full_dir)\n",
    "\n",
    "## Get the filename for well-level intensities for a given barcode and well\n",
    "## input:\n",
    "##    barcode: a plate barcode, e.g. '210406_combo_71'\n",
    "##    well: a well of interest, e.g. 'D06'\n",
    "## output:\n",
    "##    full path/filename of the well-level data\n",
    "def get_well_file(barcode, well):\n",
    "    date = date_from_barcode(barcode)\n",
    "    data_dir = get_data_dir(barcode)\n",
    "    ### example file style\n",
    "    f1 = barcode+\".result.\"+well+\"[test].csv\"\n",
    "    #f2 = barcode+\".result.\"+well+\"[test].csv\"\n",
    "    files = os.listdir(data_dir)\n",
    "    if f1 in files:\n",
    "        well_file = os.path.join(data_dir, f1)\n",
    "    else:\n",
    "        print(\"well csv not found!\")\n",
    "    return(well_file)\n",
    "\n",
    "## Read the well-level data for a given well and barcode\n",
    "## input:\n",
    "##    barcode: a plate barcode, e.g. '210406_combo_71'\n",
    "##    well: a well of interest, e.g. 'D06'\n",
    "## output:\n",
    "##    a pandas dataframe of dye intensities for individual cells\n",
    "def read_well_data(barcode, well):\n",
    "    ff = get_well_file(barcode, well)\n",
    "    df = pd.read_csv(ff)\n",
    "    return(df)\n",
    "\n",
    "## Re-name columns of well-level dataframe for LDR, DNA, EDU, etc.\n",
    "## input: original data frame read from csv\n",
    "## output: data frame with re-names columns\n",
    "def rename_df_columns(df, silent=True, hoechst_as_dna=False):\n",
    "    col_dict = {}\n",
    "    ### check for well name\n",
    "    if 'Well Name' in df.columns:\n",
    "        if not silent: print(\"'Well Name' column found -- re-naming as 'well'\")\n",
    "        col_dict['Well Name'] = 'well'\n",
    "    else:\n",
    "        print(df.columns)\n",
    "        if not silent: print('Well Name column not found')\n",
    "        return(df)\n",
    "    ### check for LDRint\n",
    "    if 'ldrint' in df.columns:\n",
    "        if not silent: print(\"'ldrint' column found -- re-naming as 'ldr'\")\n",
    "        col_dict['ldrint'] = 'ldr'\n",
    "    else:\n",
    "        print(df.columns)\n",
    "        if not silent: print('ldrint column not found')\n",
    "        return(df)\n",
    "    ### check for DNAcontent/Hoechst\n",
    "    dna_col1 = 'Cell: DNAcontent (DD-bckgrnd)'\n",
    "    dna_col2 = 'Cell: DNAcontent (DDD-bckgrnd)'\n",
    "    hoechst1 = 'Cell: HoechstINT (DD-bckgrnd)'\n",
    "    hoechst2 = 'Cell: HoechstINT (DDD-bckgrnd)'\n",
    "    check_dna1 = dna_col1 in df.columns\n",
    "    check_dna2 = dna_col2 in df.columns\n",
    "    check_hoechst1 = hoechst1 in df.columns\n",
    "    check_hoechst2 = hoechst2 in df.columns\n",
    "    if not (check_dna1 or check_dna2 or check_hoechst1 or check_hoechst2):\n",
    "        if not silent: print(df.columns)\n",
    "        if not silent: print('DNA column not found')\n",
    "    else:\n",
    "        ### if hoechst_as_dna, use the HoechstINT column as DNA if available\n",
    "        if hoechst_as_dna:\n",
    "            if check_hoechst1 and check_hoechst2:\n",
    "                print('Warning: Two HoechstINT columns -- using ' + \"'\"+hoechst2+\"'\")\n",
    "                dna_col = hoechst2\n",
    "            elif check_hoechst1: dna_col = hoechst1\n",
    "            elif check_hoechst2: dna_col = hoechst2\n",
    "            elif check_dna1 and check_dna2:\n",
    "                print('Warning: Two DNAcontent columns -- using ' + \"'\"+dna_col2+\"'\")\n",
    "                dna_col = dna_col2\n",
    "            elif check_dna1: dna_col = dna_col1\n",
    "            elif check_dna2: dna_col = dna_col2\n",
    "        ### otherwise use DNAConent column as DNA\n",
    "        else:\n",
    "            if check_dna1 and check_dna2:\n",
    "                print('Warning: Two DNAcontent columns -- using ' + \"'\"+dna_col2+\"'\")\n",
    "                dna_col = dna_col2\n",
    "            elif check_dna1: dna_col = dna_col1\n",
    "            elif check_dna2: dna_col = dna_col2\n",
    "            elif check_hoechst1 and check_hoechst2:\n",
    "                print('Warning: Two HoechstINT columns -- using ' + \"'\"+hoechst2+\"'\")\n",
    "                dna_col = hoechst2\n",
    "            elif check_hoechst1: dna_col = hoechst1\n",
    "            elif check_hoechst2: dna_col = hoechst2\n",
    "        if not silent: print(\"'\"+dna_col+\"'\"+\" column found -- re-naming as 'dna'\")\n",
    "        col_dict[dna_col] = 'dna'\n",
    "    ### check for Edu (raw)\n",
    "    if 'Cell: EdUrawINT (DDD-bckgrnd)' in df.columns:\n",
    "        if not silent: print(\"'Cell: EdUrawINT (DDD-bckgrnd)' column found -- re-naming as 'edu_raw'\")\n",
    "        col_dict['Cell: EdUrawINT (DDD-bckgrnd)'] = 'edu_raw'\n",
    "    elif 'Cell: EdUrawINT (DD-bckgrnd)' in df.columns:\n",
    "        if not silent: print(\"'Cell: EdUrawINT (DD-bckgrnd)' column found -- re-naming as 'edu_raw'\")\n",
    "        col_dict['Cell: EdUrawINT (DD-bckgrnd)'] = 'edu_raw'\n",
    "    ### check for Edu (background)\n",
    "    if 'Cell: EdUbackground (DDD-bckgrnd)' in df.columns:\n",
    "        if not silent: print(\"'Cell: EdUbackground (DDD-bckgrnd)' column found -- re-naming as 'edu_bg'\")\n",
    "        col_dict['Cell: EdUbackground (DDD-bckgrnd)'] = 'edu_bg'\n",
    "    elif 'Cell: EdUbackground (DD-bckgrnd)' in df.columns:\n",
    "        if not silent: print(\"'Cell: EdUbackground (DD-bckgrnd)' column found -- re-naming as 'edu_bg'\")\n",
    "        col_dict['Cell: EdUbackground (DD-bckgrnd)'] = 'edu_bg'\n",
    "    ### re-name data-frame columns\n",
    "    df = df.rename(columns=col_dict)\n",
    "    if 'edu_raw' in df.columns and 'edu_bg' in df.columns:\n",
    "        df['edu'] = df.edu_raw - df.edu_bg\n",
    "    return(df)\n",
    "\n",
    "def read_and_rename_well_data(barcode, well, silent = False, hoechst_as_dna=False):\n",
    "    df = read_well_data(barcode, well)\n",
    "    df = rename_df_columns(df, silent = silent, hoechst_as_dna=hoechst_as_dna)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "## Get all wells with data for a given plate\n",
    "## input:\n",
    "##    barcode: a plate barcode, e.g. '210406_combo_71'\n",
    "## output:\n",
    "##    A list of wells, e.g. ['C03', 'C04', ... , 'N22']\n",
    "def get_all_wells(barcode):\n",
    "    data_dir = get_data_dir(barcode)\n",
    "    wells_with_data = []\n",
    "    all_wells = get_well_names(\"all_wells\")\n",
    "    for well in all_wells:\n",
    "        ### example file style\n",
    "        f1 = barcode+\".result.\"+well+\"[test].csv\"\n",
    "        f1_full = os.path.join(data_dir, f1)\n",
    "        check = os.path.exists( f1_full )\n",
    "        if check:\n",
    "            wells_with_data.append(well)\n",
    "    wells_with_data.sort()\n",
    "    return(wells_with_data)\n",
    "\n",
    "### maybe not necessary for LDR intensity data?\n",
    "#def read_all_wells(barcode):\n",
    "#    wells = get_all_wells(barcode)\n",
    "#    df_list = [read_well_data(barcode, well) for well in wells]\n",
    "#    return(df_list)\n",
    "\n",
    "def get_ldr_cutoff(barcode, well, peak_loc = 1.2, silent=False, hoechst_as_dna=False):\n",
    "    #df = read_well_data(barcode, well)\n",
    "    #df = rename_df_columns(df)\n",
    "    df = read_and_rename_well_data(barcode, well, silent, hoechst_as_dna=hoechst_as_dna)\n",
    "    ldr_gates, ldr_lims = dcf_int.get_ldrgates(ldrint = df['ldr'], peak_loc=peak_loc) ## 1.2 is default\n",
    "    return(ldr_gates[1])\n",
    "\n",
    "def get_ldr_cutoff_many(barcode, wells, peak_loc = 1.2, silent=True, hoechst_as_dna=False):\n",
    "    ldrs = [get_ldr_cutoff(barcode, well, peak_loc = peak_loc, silent=silent, hoechst_as_dna=hoechst_as_dna) for well in wells]\n",
    "    return(ldrs)\n",
    "\n",
    "### note: file location hard-coded, only for wsl on my desktop right now\n",
    "def load_well_metadata(name = 'meta', folder=None, file='single_timepoint_cleaned_from_raw_2023-06-08.parquet'):\n",
    "    ### read parquet file w/ all metadata\n",
    "    if folder is None:\n",
    "        folder = \"/mnt/c/Users/NC168/git/LINCS_combos/data/cleaned/\"\n",
    "    full_file = os.path.join(folder, file)\n",
    "    df = pd.read_parquet(full_file)\n",
    "    globals()[name] = df\n",
    "    \n",
    "def get_wells(barcode, cell_line):\n",
    "    ### get only the wells for a certain cell line on a given barcode\n",
    "    if not 'meta' in globals(): load_well_metadata()\n",
    "    #query = \" cell_line == 'SUM1315' & barcode == '201117_combo_33' \"\n",
    "    query = \"cell_line == '\"+cell_line+\"' & barcode == '\"+barcode+\"'\"\n",
    "    meta_sub = meta.query(query)\n",
    "    wells = list(meta_sub.well)\n",
    "    wells.sort()\n",
    "    return(wells)\n",
    "\n",
    "def get_cell_lines_on_plate(barcode):\n",
    "    if not 'meta' in globals(): load_well_metadata()\n",
    "    query = \"barcode == '\"+barcode+\"'\"\n",
    "    meta_sub = meta.query(query)\n",
    "    cell_lines = meta_sub.cell_line.unique()\n",
    "    return(cell_lines)\n",
    "\n",
    "def get_ldr_cutoffs_plate(barcode, peak_loc = 1.2, silent = True):\n",
    "    cell_lines = get_cell_lines_on_plate(barcode)\n",
    "    df = get_ldr_cutoffs_cell_line_and_barcode(barcode, cell_lines, peak_loc=peak_loc, silent=silent)\n",
    "    return(df)\n",
    "\n",
    "def get_ldr_cutoffs_cell_line_and_barcode(barcode, cell_lines, peak_loc=1.2, silent = True):\n",
    "    df_list = []\n",
    "    for cell_line in cell_lines:\n",
    "        if not silent: print(cell_line)\n",
    "        wells = get_wells(barcode, cell_line)\n",
    "        ldrs = get_ldr_cutoff_many(barcode, wells, peak_loc=peak_loc)\n",
    "        d = {'well':wells, 'ldr_cutoff': ldrs, 'barcode':barcode, 'cell_line': cell_line}\n",
    "        df_tmp = pd.DataFrame(data=d)\n",
    "        df_list.append(df_tmp)\n",
    "    df = pd.concat(df_list)\n",
    "    return(df)\n",
    "\n",
    "## x_lims: tuple of x limits for the plot\n",
    "## y_lims: tuple of y limits for the plot\n",
    "def plot_ldr(df, peak_loc = 1.2, scatter = True, silent = True, show_fig = True, \n",
    "             fig=None, outer=None, i=None, title = \"\", x_lims=None, y_lims=None, add_ldr_line = None):\n",
    "    ldr_gates, ldr_lims = dcf_int.get_ldrgates(ldrint = df['ldr'], peak_loc=peak_loc)\n",
    "    df = df.copy()\n",
    "    ldr_cutoff = ldr_gates[1]\n",
    "    #df = df.query(\"ldr > 0\")\n",
    "    #df['ldr'] = [x if x>0 else 10**(-10) for x in df.ldr]\n",
    "    #### set negative ldr and dna values to the minimum positive values (just for plotting)\n",
    "    df_pos1 = df.query(\"ldr > 0\")\n",
    "    min_ldr = np.min(df_pos1.ldr)\n",
    "    df_pos2 = df.query(\"dna > 0\")\n",
    "    min_dna = np.min(df_pos2.dna)\n",
    "    df['ldr'] = [x if x>0 else min_ldr for x in df.ldr]\n",
    "    df['dna'] = [x if x>0 else min_dna for x in df.dna]\n",
    "    if scatter:\n",
    "        fig = mg.plot_ldr_dna_scatter(np.log10(df.dna), np.log10(df.ldr), ldr_cutoff, \n",
    "                                            dna_gates=None, plot_ldr_log10=True, is_ldrint=True,\n",
    "                                           show_fig=show_fig, fig = fig, outer=outer, i=i,\n",
    "                                     title=title, x_lims=x_lims, y_lims=y_lims, add_ldr_line = add_ldr_line)\n",
    "    else:\n",
    "        fig = mg.ldr_gating(np.log10(df.ldr), ldr_cutoff, nbins = 20)\n",
    "    return(fig)\n",
    "\n",
    "def plot_ldr_well(barcode, well, peak_loc = 1.2, scatter = True, silent = True, \n",
    "                  show_fig = True, fig=None, outer=None, i=None, title=\"\", x_lims=None, \n",
    "                  y_lims=None, hoechst_as_dna=False, add_ldr_line=None):\n",
    "    df = read_and_rename_well_data(barcode, well, silent, hoechst_as_dna=hoechst_as_dna)\n",
    "    #df = df.query(\"ldr > 0\")\n",
    "    #df['ldr'] = [x if x>0 else 10**(-10) for x in df.ldr]\n",
    "    #df_pos1 = df.query(\"ldr > 0\")\n",
    "    #min_ldr = np.min(df_pos1.ldr)\n",
    "    #df_pos2 = df.query(\"dna > 0\")\n",
    "    #min_dna = np.min(df_pos2.dna)\n",
    "    #df['ldr'] = [x if x>0 else min_ldr for x in df.ldr]\n",
    "    #df['dna'] = [x if x>0 else min_dna for x in df.dna]\n",
    "    fig = plot_ldr(df, peak_loc = peak_loc, scatter = scatter, silent = silent, \n",
    "                   show_fig = show_fig, fig = fig, outer=outer, i=i, title = title,x_lims=x_lims,\n",
    "                   y_lims=y_lims, add_ldr_line = add_ldr_line)\n",
    "    return(fig)\n",
    "\n",
    "def plot_ldr_many(barcode, wells, peak_loc = 1.2, scatter = False, silent = True, hoechst_as_dna=False):\n",
    "    for well in wells:\n",
    "        df = read_and_rename_well_data(barcode, well, silent, hoechst_as_dna=hoechst_as_dna)\n",
    "        plot_ldr(df, peak_loc = peak_loc, scatter = scatter)\n",
    "\n",
    "def plot_ldr_pdf(barcode, wells, peak_loc = 1.2, figname = \"test_ldr.pdf\", scatter = True, \n",
    "                 silent = True, show_fig = True, hoechst_as_dna=False):\n",
    "    pdf_pages = PdfPages(figname)\n",
    "    fig_list = []\n",
    "    for i in range(len(wells)):\n",
    "        well = wells[i]\n",
    "        well_meta = get_well_meta(barcode, well)\n",
    "        cell_line = list(well_meta.cell_line)[0]\n",
    "        trt1 = list(well_meta.agent1)[0]\n",
    "        trt2 = list(well_meta.agent2)[0]\n",
    "        conc1 = list(well_meta.concentration1_chr)[0]\n",
    "        conc2 = list(well_meta.concentration2_chr)[0]\n",
    "        df = read_and_rename_well_data(barcode, well, silent, hoechst_as_dna=hoechst_as_dna)\n",
    "        ldr_gates, ldr_lims = dcf_int.get_ldrgates(ldrint = df['ldr'], peak_loc=peak_loc)\n",
    "        ldr_cutoff = ldr_gates[1]\n",
    "        df = df.query(\"ldr > 0\")\n",
    "        #df['ldr'] = [x if x>0 else 10**(-10) for x in df.ldr]\n",
    "        if scatter:\n",
    "            fig = mg.plot_ldr_dna_scatter(np.log10(df.dna), np.log10(df.ldr), ldr_cutoff, dna_gates=None, \n",
    "                                          plot_ldr_log10=True, is_ldrint=True, show_fig = show_fig)\n",
    "        else:\n",
    "            fig = mg.ldr_gating(np.log10(df.ldr), ldr_cutoff, nbins = 20)\n",
    "        fig_title = str(trt1) + \": \"+ str(conc1) + \" uM, \" + str(trt2) + \": \" + str(conc2) + \" uM\"\n",
    "        #print(fig_title)\n",
    "        fig.suptitle(well + \"\\n\" + fig_title, fontsize=12)\n",
    "        fig_list.append(fig)\n",
    "        plt.close()\n",
    "        pdf_pages.savefig(fig)\n",
    "    pdf_pages.close()\n",
    "    return(fig_list)\n",
    "\n",
    "def test_regate(barcode, cell_line, peak_loc = 1.2, figname = \"test_figure\", scatter = True, silent = True, test = True, \n",
    "                show_fig = False, hoechst_as_dna=False):\n",
    "    path1 = os.path.join('temp_regating', 'csv')\n",
    "    path2 = os.path.join('temp_regating', 'pdf')\n",
    "    if not os.path.exists(path1):\n",
    "        os.makedirs(path1)\n",
    "    if not os.path.exists(path2):\n",
    "        os.makedirs(path2)\n",
    "    wells = get_wells(barcode, cell_line)\n",
    "    df_list = []\n",
    "    csv_file = os.path.join(path1, figname+'.csv')\n",
    "    pdf_file = os.path.join(path2, figname+'.pdf')\n",
    "    plot_list = plot_ldr_pdf(barcode, wells, peak_loc, figname=pdf_file, scatter=scatter, silent=silent, \n",
    "                             show_fig=show_fig, hoechst_as_dna=hoechst_as_dna)\n",
    "    print('figures written to: ' + pdf_file)\n",
    "    for well in wells:\n",
    "        df = read_and_rename_well_data(barcode, well, silent, hoechst_as_dna=hoechst_as_dna)\n",
    "        df_tmp = dcf_int.get_counts_df(df=df, barcode=barcode, well=well, peak_loc = peak_loc)\n",
    "        df_list.append(df_tmp)\n",
    "    df_out = pd.concat(df_list)\n",
    "    df_out.to_csv(csv_file)\n",
    "    return(df_out, plot_list)\n",
    "\n",
    "def plot_wells_ldr(barcode, cell_line, peak_loc=1.2, scatter = True, silent=True,\n",
    "                   figname = None, output_dir=\"default_gating\", hoechst_as_dna=False):\n",
    "    if figname is None: figname=barcode+'_'+cell_line+'_'+'peak_loc_'+str(peak_loc)\n",
    "    if not 'meta' in globals(): load_well_metadata()\n",
    "    wells = get_wells(barcode, cell_line)\n",
    "    df_list = []\n",
    "    df_full_list = []\n",
    "    for well in wells:\n",
    "        df = read_and_rename_well_data(barcode, well, silent, hoechst_as_dna=hoechst_as_dna)\n",
    "        #df = df.query(\"ldr > 0\")\n",
    "        df_tmp = dcf_int.get_counts_df(df=df, barcode=barcode, well=well, peak_loc = peak_loc)\n",
    "        df_list.append(df_tmp)\n",
    "        df_full_list.append(df)\n",
    "    df2 = pd.concat(df_list)\n",
    "    df_full = pd.concat(df_full_list)\n",
    "    df_pos1 = df_full.query(\"ldr > 0\")\n",
    "    y_log = np.log10(df_pos1.ldr)\n",
    "    y_lims = (min(y_log), max(y_log))\n",
    "    print(y_lims)\n",
    "    df_pos2 = df_full.query(\"dna > 0\")\n",
    "    x_log = np.log10(df_pos2.dna)\n",
    "    x_lims = (min(x_log)-0.2, max(x_log)+0.2)\n",
    "    ### save counts data frame to csv\n",
    "    csv1 = \"all_wells_\" + figname + \".csv\"\n",
    "    csv1_full = os.path.join(output_dir, csv1)\n",
    "    df2.to_csv(csv1_full)\n",
    "    ### plot wells that changed\n",
    "    fig_list = []\n",
    "    pdf = \"all_wells_scatter_\" + figname + \".pdf\"\n",
    "    pdf_full = os.path.join(output_dir, pdf)\n",
    "    pdf_pages = PdfPages(pdf_full)\n",
    "    nb_plots = len(df2.well)\n",
    "    plots_per_page = 6\n",
    "    for i in range(nb_plots):\n",
    "        #print(i)\n",
    "        if i % plots_per_page == 0:\n",
    "            fig = plt.figure(figsize=(8.5, 11))\n",
    "            outer = GridSpec(3, 2, wspace=0.2, hspace=0.5)\n",
    "        well = wells[i]\n",
    "        #print(well)\n",
    "        df = read_and_rename_well_data(barcode, well, silent=True, hoechst_as_dna=hoechst_as_dna)\n",
    "        ### get well metadata\n",
    "        well_meta = get_well_meta(barcode, well)\n",
    "        cell_line = list(well_meta.cell_line)[0]\n",
    "        trt1 = list(well_meta.agent1)[0]\n",
    "        trt2 = list(well_meta.agent2)[0]\n",
    "        conc1 = list(well_meta.concentration1_chr)[0]\n",
    "        conc2 = list(well_meta.concentration2_chr)[0]\n",
    "        ### add title to figures\n",
    "        fig_title = str(trt1) + \": \"+ str(conc1) + \" uM, \" + str(trt2) + \": \" + str(conc2) + \" uM\"\n",
    "        fig_title = well+\", peak_loc = \"+str(peak_loc)+\"\\n\"+fig_title\n",
    "    \n",
    "        i_page = i % plots_per_page\n",
    "        ### make figures\n",
    "        fig_tmp = plot_ldr_well(barcode, well, peak_loc = peak_loc, scatter = scatter, \n",
    "                                 silent = silent, show_fig = False, fig = fig, outer = outer, i = i_page,\n",
    "                               title = fig_title, x_lims=x_lims, y_lims=y_lims, hoechst_as_dna=hoechst_as_dna)\n",
    "        #plt.close()\n",
    "        fig_list.append(fig_tmp)\n",
    "        if (i + 1) % plots_per_page == 0 or (i + 1) == nb_plots:\n",
    "               plt.tight_layout()\n",
    "               pdf_pages.savefig()\n",
    "               plt.close('all')\n",
    "    pdf_pages.close()\n",
    "    return([df2, fig_list])\n",
    "\n",
    "def get_well_meta(barcode, well):\n",
    "    query = \"barcode == '\"+ barcode+ \"' & well == '\"+ well + \"'\"\n",
    "    df_sub = meta.query(query)\n",
    "    return(df_sub)\n",
    "\n",
    "def plot_ldr_cutoff_change(barcode, cell_line, peak_loc, scatter = True, silent=True, \n",
    "                           default_peak_loc = 1.2, figname = None,\n",
    "                          #output_dir=\"/mnt/y/lsp-analysis/LINCS-combinations/re_gating/new_gating\"):\n",
    "                           output_dir=\"temp_regating\",\n",
    "                          hoechst_as_dna=False):\n",
    "    if figname is None: figname=barcode+'_'+cell_line+'_'+'peak_loc_'+str(peak_loc)\n",
    "    if not 'meta' in globals(): load_well_metadata()\n",
    "    wells = get_wells(barcode, cell_line)\n",
    "    df_list_orig = []\n",
    "    df_list_new = []\n",
    "    for well in wells:\n",
    "        df = read_and_rename_well_data(barcode, well, silent, hoechst_as_dna=hoechst_as_dna)\n",
    "        #df = df.query(\"ldr > 0\")\n",
    "        df_tmp_new = dcf_int.get_counts_df(df=df, barcode=barcode, well=well, peak_loc = peak_loc)\n",
    "        df_list_new.append(df_tmp_new)\n",
    "        df_tmp_orig = dcf_int.get_counts_df(df=df, barcode=barcode, well=well, peak_loc = default_peak_loc)\n",
    "        df_list_orig.append(df_tmp_orig)\n",
    "    df_orig = pd.concat(df_list_orig)\n",
    "    df_new = pd.concat(df_list_new)\n",
    "    ### add suffixes to measured columns in each data frame\n",
    "    df_orig2 = df_orig.rename(columns={c: c+'_orig' for c in df_orig.columns if c not in ['barcode', 'well']})\n",
    "    df_new2 = df_new.rename(columns={c: c+'_new' for c in df_new.columns if c not in ['barcode', 'well']})\n",
    "    ### join the data frames\n",
    "    df2 = df_orig2.merge(df_new2, on = ['barcode', 'well'], how = 'inner')\n",
    "    meta_select = meta[['barcode', 'cell_line', 'well', 'agent1', 'concentration1_chr', 'agent2', 'concentration2_chr', 'timepoint']]\n",
    "    df2 = df2.merge(meta_select, on = ['barcode', 'well'], how = 'left')\n",
    "    cols = ['barcode', 'well', 'cell_count__dead_orig', 'cell_count__dead_new', 'cell_count_orig', 'cell_count_new', \n",
    "                  'ldr_cutoff_orig', 'ldr_cutoff_new', 'cell_line','agent1', 'concentration1_chr', 'agent2', \n",
    "                  'concentration2_chr', 'timepoint']\n",
    "    last_cols = [ x for x in df2.columns if x not in cols ]\n",
    "    cols.extend(last_cols)\n",
    "    df2 = df2[cols]\n",
    "    df2['label'] = df2.apply(lambda row: row.well if row.ldr_cutoff_orig != row.ldr_cutoff_new else \"\", axis=1)\n",
    "    df2_sub = df2.query(\"ldr_cutoff_orig != ldr_cutoff_new\")\n",
    "    df2_sub.reset_index(drop=True, inplace=True)\n",
    "    ### plot new vs. old cutoffs, live/dead counts\n",
    "    gg1 = pw.load_ggplot(ggplot(df2, aes(x = \"ldr_cutoff_orig\", y = \"ldr_cutoff_new\")) +\\\n",
    "        geom_point(alpha = 0.5) +\\\n",
    "        geom_label(aes(label=\"label\"), alpha = 0.5, nudge_x = 0.05, nudge_y = 0.05), figsize=(3,3))\n",
    "    gg2 = pw.load_ggplot(ggplot(df2, aes(x = \"cell_count__dead_orig\", y = \"cell_count__dead_new\")) +\\\n",
    "        geom_point(alpha = 0.5) +\\\n",
    "        geom_label(aes(label=\"label\"), alpha = 0.5, nudge_x = 20, nudge_y = 5), figsize=(3,3))\n",
    "    gg3 = pw.load_ggplot(ggplot(df2, aes(x = \"cell_count_orig\", y = \"cell_count_new\")) +\\\n",
    "        geom_point(alpha = 0.5) +\\\n",
    "        geom_label(aes(label=\"label\"), alpha = 0.5, nudge_x = 100, nudge_y = 100), figsize=(3,3))\n",
    "    \n",
    "    gg = (gg1|gg2|gg3)\n",
    "    pdf1 = figname + str(\"_summary.pdf\")\n",
    "    pdf1_full = os.path.join(output_dir, pdf1)\n",
    "    gg.savefig(pdf1_full)\n",
    "                               \n",
    "    ### plot wells that changed\n",
    "    fig_list_orig = []\n",
    "    fig_list_new = []\n",
    "    pdf2 = figname + str(\"_wells_changed.pdf\")\n",
    "    pdf2_full = os.path.join(output_dir, pdf2)\n",
    "    pdf_pages = PdfPages(pdf2_full)\n",
    "    nb_rows = len(df2_sub.well)\n",
    "    rows_per_page = 3\n",
    "    for i in range(nb_rows):\n",
    "        if i % rows_per_page == 0:\n",
    "            fig = plt.figure(figsize=(8.5, 11))\n",
    "            outer = GridSpec(3, 2, wspace=0.2, hspace=0.5)\n",
    "        well = df2_sub.well[i]\n",
    "        df = read_and_rename_well_data(barcode, well, silent=True, hoechst_as_dna=hoechst_as_dna)\n",
    "    \n",
    "        ### get well metadata\n",
    "        well_meta = get_well_meta(barcode, well)\n",
    "        cell_line = list(well_meta.cell_line)[0]\n",
    "        trt1 = list(well_meta.agent1)[0]\n",
    "        trt2 = list(well_meta.agent2)[0]\n",
    "        conc1 = list(well_meta.concentration1_chr)[0]\n",
    "        conc2 = list(well_meta.concentration2_chr)[0]\n",
    "        ### add title to figures\n",
    "        fig_title = str(trt1) + \": \"+ str(conc1) + \" uM, \" + str(trt2) + \": \" + str(conc2) + \" uM\"\n",
    "        fig_title_orig = well+\", peak_loc = \"+str(default_peak_loc)+\" (default)\"+\"\\n\"+fig_title\n",
    "        fig_title_new = well+\", peak_loc = \"+str(peak_loc)+\"\\n\"+fig_title\n",
    "    \n",
    "        i_page = i % rows_per_page\n",
    "        ### make figures for new and old peak_loc values\n",
    "        fig_orig = plot_ldr_well(barcode, well, peak_loc = default_peak_loc, scatter = scatter, \n",
    "                                 silent = silent, show_fig = False, fig = fig, outer = outer, i = 2*i_page,\n",
    "                                title = fig_title_orig, hoechst_as_dna=hoechst_as_dna)\n",
    "        #plt.close()\n",
    "        fig_new = plot_ldr_well(barcode, well, peak_loc = peak_loc, scatter = scatter, \n",
    "                                 silent = silent, show_fig = False, fig = fig, outer = outer, i = 2*i_page+1,\n",
    "                               title = fig_title_new, hoechst_as_dna=hoechst_as_dna)\n",
    "        #plt.close()\n",
    "        fig_list_orig.append(fig_orig)\n",
    "        fig_list_new.append(fig_new)\n",
    "        if (i + 1) % rows_per_page == 0 or (i + 1) == nb_rows:\n",
    "               plt.tight_layout()\n",
    "               pdf_pages.savefig()\n",
    "               plt.close('all')\n",
    "    pdf_pages.close()\n",
    "    ### write data frames to csv files\n",
    "    # write cell counts for all wells\n",
    "    csv1 = figname + str(\"_all_wells.csv\")\n",
    "    csv1_full = os.path.join(output_dir, csv1)\n",
    "    df2.to_csv(csv1_full)\n",
    "    # write cell counts for only wells where counts changed\n",
    "    csv2 = figname + str(\"_wells_changed.csv\")\n",
    "    csv2_full = os.path.join(output_dir, csv2)\n",
    "    df2_sub.to_csv(csv2_full)\n",
    "    \n",
    "    return([df2, df2_sub, gg, fig_list_orig, fig_list_new])\n",
    "\n",
    "### plot LDR cutoffs\n",
    "def plot_flagged_wells_ldr(barcode, cell_line, well_df, figname = None, peak_loc = 1.2, output_dir=\"default_gating\", write_pdf=True,\n",
    "                          hoechst_as_dna=False):\n",
    "    if figname is None: figname=barcode+'_'+cell_line+'_'+'peak_loc_'+str(peak_loc)\n",
    "    query = \"cell_line == '\"+cell_line+\"' & barcode == '\"+barcode+\"'\"\n",
    "    well_df = well_df.query(query)\n",
    "    wells = get_wells(barcode, cell_line)\n",
    "    df_list = []\n",
    "    for well in wells:\n",
    "        df = read_and_rename_well_data(barcode, well, silent=True,hoechst_as_dna=hoechst_as_dna)\n",
    "        #df = df.query(\"ldr > 0\")\n",
    "        df_tmp = dcf_int.get_counts_df(df=df, barcode=barcode, well=well, peak_loc = peak_loc)\n",
    "        df_list.append(df_tmp)\n",
    "    df = pd.concat(df_list)\n",
    "    #return(df)\n",
    "    df['flagged'] = [\"flagged\" if x in list(well_df.well) else \"not_flagged\" for x in df.well]\n",
    "    gg = ggplot(df, aes(x = 'flagged', y = 'ldr_cutoff')) + geom_boxplot() + geom_jitter()\n",
    "\n",
    "    csv_file = \"flagged_wells_\" + figname + \".csv\"\n",
    "    csv_full = os.path.join(output_dir, csv_file)\n",
    "    pdf = \"boxplot_ldr_cutoff_\" + figname + \".pdf\"\n",
    "    pdf_full = os.path.join(output_dir, pdf)\n",
    "    \n",
    "    if write_pdf: gg.save(pdf_full, format = \"pdf\", width = 2.5, height = 3)\n",
    "    well_df.to_csv(csv_full)\n",
    "    return(df, gg)\n",
    "    \n",
    "def plot_problem_plate(barcode, cell_line, peak_loc=1.2, df_wells=None, scatter=True, silent=True, output_dir=\"default_gating\",\n",
    "                      hoechst_as_dna=False):\n",
    "    final_dir = os.path.join(output_dir, cell_line + \"_\" + barcode)\n",
    "    if not os.path.exists(final_dir): os.makedirs(final_dir)\n",
    "    ### plot ldr vs. dna scatterplots for all wells:\n",
    "    plot_wells_ldr(barcode, cell_line, peak_loc=peak_loc, scatter = scatter, silent=silent,\n",
    "                   figname = None, output_dir=final_dir, hoechst_as_dna=hoechst_as_dna)\n",
    "    ### plot ldr cutoffs for flagged vs. unflagged wells\n",
    "    if df_wells is not None:\n",
    "        plot_flagged_wells_ldr(barcode, cell_line, df_wells, output_dir = final_dir, write_pdf=True, hoechst_as_dna=hoechst_as_dna)\n",
    "\n",
    "def plot_all_problem_plates(peak_loc=1.2, scatter=True, silent=True, output_dir = \"default_gating\", hoechst_as_dna=False):\n",
    "    df_plates, df_wells = get_plates_to_regate()\n",
    "    n_plates = len(df_plates.barcode)\n",
    "    print(\"plotting LDR for \" + str(n_plates) + \" cell lines/plates\")\n",
    "    for i in range(n_plates):\n",
    "        barcode = list(df_plates.barcode)[i]\n",
    "        cell_line = list(df_plates.cell_line)[i]\n",
    "        print(\"Plate \" + str(i) + \": \"+ cell_line + \" \" + barcode)\n",
    "        plot_problem_plate(barcode, cell_line, peak_loc=peak_loc, df_wells=df_wells, scatter=scatter,\n",
    "                           silent=silent, output_dir=output_dir, hoechst_as_dna=hoechst_as_dna)\n",
    "        \n",
    "\n",
    "### Todo:\n",
    "## 1) def plot_problem_plate(): \n",
    "        ## steps:\n",
    "        ## 1) call plot_wells_ldr to create plots of all wells for a problem plate-- write to pdf\n",
    "        ## 2) load problem well metadata, create box plot of LDR cutoffs for \"flagged wells\" vs. \"unflagged wells\" -- print to pdf\n",
    "        ## 3) save both (plus a csv, already written from plot_wells_ldr function) to \"default_gating/\n",
    "                               \n",
    "## 2) loop over all bad plates/cell lines and plot LDR gating with default options\n",
    "    ## for each, look at box plots and well-level scatter plots and pick a cutoff in-between the \"flagged\" and \"non-flagged\" ldr cutoffs.\n",
    "    ## put new cutoffs manually into a dict/dataframe\n",
    "\n",
    "## 3) call plot_LDR_cutoff_change with the new LDR cutoffs to write new plots and data to files\n",
    "\n",
    "## Define a dictionary with the local folder name for experiments on each date\n",
    "def define_regating_df(name = 'regate_df'):\n",
    "    #barcode = '211015_combo_176'\n",
    "    #cell_line = 'SUM1315'\n",
    "    data = [\n",
    "        ### Time zero plates\n",
    "        ## note: plate 62 gating is fine with default peak_loc=1.2 on all but one well -- not sure why it was bad before\n",
    "        {'barcode': '210406_combo_62', 'cell_line': 'SUM1315', 'peak_loc': 1.2, 'hoechst_as_dna': False},\n",
    "        {'barcode': '210423_combo_78', 'cell_line': 'SUM185PE', 'peak_loc': 2, 'hoechst_as_dna': False},\n",
    "        ### End-time plates\n",
    "        ### note: wells I06 and J07 -- almost 500 dead cells dead sub-g1, only ~50 LDR positive -- dna gating issue, not LDR gating?\n",
    "        {'barcode': '210226_combo_51', 'cell_line': 'HCC1937', 'peak_loc': 1.2, 'hoechst_as_dna': True}, #using Hoechst column as dna fixes dead count\n",
    "        ### note: only well I11 -- almost 500 dead cells dead sub-g1, only ~50 LDR positive -- dna gating issue, not LDR gating?\n",
    "        ###  note: well I18 -- high subg1 dead cells\n",
    "        {'barcode': '210226_combo_52', 'cell_line': 'HCC1937', 'peak_loc': 1.2, 'hoechst_as_dna': True}, #using Hoechst column as dna fixes dead count\n",
    "        {'barcode': '210226_combo_53', 'cell_line': 'HCC1937', 'peak_loc': 1.2, 'hoechst_as_dna': True}, #using Hoechst column as dna fixes dead count\n",
    "        {'barcode': '210226_combo_54', 'cell_line': 'HCC1937', 'peak_loc': 1.2, 'hoechst_as_dna': True}, #using Hoechst column as dna fixes dead count\n",
    "        {'barcode': '210226_combo_55', 'cell_line': 'HCC1937', 'peak_loc': 1.2, 'hoechst_as_dna': True}, #using Hoechst column as dna fixes dead count\n",
    "        {'barcode': '210226_combo_56', 'cell_line': 'HCC1937', 'peak_loc': 1.2, 'hoechst_as_dna': True}, #using Hoechst column as dna fixes dead count\n",
    "        {'barcode': '210226_combo_57', 'cell_line': 'HCC1937', 'peak_loc': 1.2, 'hoechst_as_dna': True}, #using Hoechst column as dna fixes dead count\n",
    "        {'barcode': '210302_combo_59', 'cell_line': 'HCC1937', 'peak_loc': 1.2, 'hoechst_as_dna': True}, #using Hoechst column as dna fixes dead count\n",
    "        {'barcode': '210302_combo_60', 'cell_line': 'HCC1937', 'peak_loc': 1.2, 'hoechst_as_dna': True}, #using Hoechst column as dna fixes dead count\n",
    "        {'barcode': '210302_combo_61', 'cell_line': 'HCC1937', 'peak_loc': 1.2, 'hoechst_as_dna': True}, #using Hoechst column as dna fixes dead count\n",
    "        {'barcode': '210406_combo_69', 'cell_line': 'SUM1315', 'peak_loc': 1.2, 'hoechst_as_dna': False}, #regating w/ default values gives low dead count\n",
    "        {'barcode': '210406_combo_70', 'cell_line': 'SUM1315', 'peak_loc': 1.2, 'hoechst_as_dna': False}, #regating w/ default values gives low dead count\n",
    "        {'barcode': '210406_combo_71', 'cell_line': 'SUM1315', 'peak_loc': 1.2, 'hoechst_as_dna': False}, #regating w/ default values gives low dead count\n",
    "        # plate 72 -- E11 is the only control well that looks bad after regating -- will be solved by trimmed mean\n",
    "        ### notes: a few non-control wells look wrong -- E05, possibly E07, F05, F19, etc.\n",
    "        ### notes: a wide range of LDR cutoffs -- from 2 to 4 -- good cutoff looks like around 3 to 3.25\n",
    "        {'barcode': '210406_combo_72', 'cell_line': 'SUM1315', 'peak_loc': 1.2, 'hoechst_as_dna': False}, #regating w/ default values gives low dead count\n",
    "        {'barcode': '210406_combo_73', 'cell_line': 'SUM1315', 'peak_loc': 1.2, 'hoechst_as_dna': False}, #regating w/ default values gives low dead count\n",
    "        {'barcode': '210406_combo_74', 'cell_line': 'SUM1315', 'peak_loc': 1.2, 'hoechst_as_dna': False}, #regating w/ default values gives low dead count\n",
    "        ### plate 75: E11 is the only control well that looks bad -- will be solved by trimmed mean\n",
    "        {'barcode': '210406_combo_75', 'cell_line': 'SUM1315', 'peak_loc': 1.2, 'hoechst_as_dna': False}, #regating w/ default values gives low dead count\n",
    "        {'barcode': '210406_combo_76', 'cell_line': 'SUM1315', 'peak_loc': 1.2, 'hoechst_as_dna': False}, #regating w/ default values gives low dead count\n",
    "        {'barcode': '210406_combo_77', 'cell_line': 'SUM1315', 'peak_loc': 1.2, 'hoechst_as_dna': False}, #regating w/ default values gives low dead count\n",
    "        {'barcode': '211005_combo_158', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211005_combo_160', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211005_combo_161', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211005_combo_162', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211005_combo_163', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211005_combo_164', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211005_combo_165', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211005_combo_166', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211015_combo_168', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211015_combo_169', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211015_combo_170', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211015_combo_171', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211015_combo_172', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211015_combo_173', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211015_combo_174', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211015_combo_175', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False},\n",
    "        {'barcode': '211015_combo_176', 'cell_line': 'SUM1315', 'peak_loc': 2.75, 'hoechst_as_dna': False}\n",
    "    ]\n",
    "    df = pd.DataFrame(data)\n",
    "    globals()[name] = df\n",
    "\n",
    "def gate_well(barcode, well, peak_loc=1.2, silent=False, hoechst_as_dna=False):\n",
    "    df = read_and_rename_well_data(barcode, well, silent, hoechst_as_dna=hoechst_as_dna)\n",
    "    df_tmp = dcf_int.get_counts_df(df=df, barcode=barcode, well=well, peak_loc = peak_loc)\n",
    "    return(df_tmp)\n",
    "\n",
    "def regate_wells(silent=True):\n",
    "    df_list2 = []\n",
    "    for i in range(regate_df.shape[0]):\n",
    "        print(i)\n",
    "        barcode = regate_df['barcode'][i]\n",
    "        cell_line = regate_df['cell_line'][i]\n",
    "        peak_loc = regate_df['peak_loc'][i]\n",
    "        hoechst_as_dna = regate_df['hoechst_as_dna'][i]\n",
    "        if not 'meta' in globals(): load_well_metadata()\n",
    "        wells = get_wells(barcode, cell_line)\n",
    "        df_list = []\n",
    "        for well in wells:\n",
    "            #df = read_and_rename_well_data(barcode, well, silent, hoechst_as_dna=hoechst_as_dna)\n",
    "            #df_tmp = dcf_int.get_counts_df(df=df, barcode=barcode, well=well, peak_loc = peak_loc)\n",
    "            df_tmp = gate_well(barcode, well, peak_loc=peak_loc, silent=silent, hoechst_as_dna=hoechst_as_dna)\n",
    "            df_list.append(df_tmp)\n",
    "        df_out = pd.concat(df_list)\n",
    "        df_list2.append(df_out)\n",
    "    df_out2 = pd.concat(df_list2)\n",
    "    return(df_out2)\n",
    "\n",
    "def get_ldr_cutoffs_all(peak_loc = 1.2):\n",
    "    if not 'folder_dict' in globals(): define_folder_dict('folder_dict')\n",
    "    df_list_full = []\n",
    "    for date in folder_dict.keys():\n",
    "        print(date)\n",
    "        plates = get_barcodes(date)\n",
    "        df_list_date=[]\n",
    "        for plate in plates:\n",
    "            print(plate)\n",
    "            df_tmp = get_ldr_cutoffs_plate(plate, peak_loc = peak_loc)\n",
    "            df_list_date.append(df_tmp)\n",
    "        df_date = pd.concat(df_list_date)\n",
    "        df_list_full.append(df_date)\n",
    "    df_full = pd.concat(df_list_full)\n",
    "    return(df_full)\n",
    "\n",
    "def get_ldr_cutoffs_fast(peak_loc=1.2):\n",
    "    if not 'meta' in globals(): load_well_metadata()\n",
    "    cutoffs = []\n",
    "    for i in range(meta.shape[0]):\n",
    "    #for i in range(50):\n",
    "        if i % 1000 == 0: print(i)\n",
    "        barcode = meta.barcode[i]\n",
    "        well = meta.well[i]\n",
    "        cutoff = get_ldr_cutoff(barcode, well, peak_loc = 1.2, silent=True)\n",
    "        cutoffs.append(cutoff)\n",
    "    return(cutoffs)\n",
    "\n",
    "def get_ldr_cutoff_i(i, peak_loc=1.2):\n",
    "    return(get_ldr_cutoff(meta.barcode[i], meta.well[i], peak_loc = 1.2, silent=True))\n",
    "\n",
    "def get_ldr_cutoffs_parallel(peak_loc=1.2, nproc = 10, batch = 1000):\n",
    "    if not 'meta' in globals(): load_well_metadata()\n",
    "    cutoffs = []\n",
    "    n_total = meta.shape[0]\n",
    "    batches = np.ceil(meta.shape[0]/batch)\n",
    "    for i in range(int(batches)):\n",
    "        print(i)\n",
    "        tic = time.time()\n",
    "        start_batch = i*batch\n",
    "        end_batch = min( (i+1)*batch, n_total)\n",
    "        range_obj = range(start_batch, end_batch)\n",
    "        pool = multiprocessing.Pool(nproc)\n",
    "        cutoffs_batch = pool.map(get_ldr_cutoff_i, range_obj)\n",
    "        #cutoffs_batch = pool.map(get_meta_i, range_obj)\n",
    "        cutoffs.extend(cutoffs_batch)\n",
    "        toc = time.time()\n",
    "        print(str(toc-tic))\n",
    "    return(cutoffs)\n",
    "\n",
    "def get_counts_well(barcode, well, peak_loc=1.2, manual_ldr_cutoff=None, plot=True):\n",
    "    df = read_and_rename_well_data(barcode, well)\n",
    "    df_out = dcf_int.get_counts_df(df=df.copy(), barcode=barcode, well=well, \n",
    "                                   peak_loc = peak_loc, manual_ldr_cutoff=manual_ldr_cutoff)\n",
    "    if plot: plot_ldr(df.copy(), peak_loc = peak_loc, add_ldr_line=manual_ldr_cutoff)\n",
    "    return(df_out)\n",
    "\n",
    "def kde_plot_wells(barcode, wells, title = \"\", add_legend=False, smoothing=1):\n",
    "    fig, ax = plt.subplots()\n",
    "    #ax.set_title(title, fontsize=12)\n",
    "    for well in wells:\n",
    "        df = read_and_rename_well_data(barcode, well, silent = True)\n",
    "        ldrint = df['ldr'].copy()\n",
    "        ldrint[ldrint < 0] = float('nan')\n",
    "        logint = np.log10(ldrint)\n",
    "        #x, y = sns.kdeplot(logint, ax=ax, color = \"grey\", alpha=0.5).get_lines()[0].get_data()\n",
    "        if add_legend:\n",
    "            meta_sub=get_well_meta(barcode=barcode, well=well)\n",
    "            trt = list(meta_sub.agent1)[0] + \" \" + list(meta_sub.concentration1_chr)[0] + \"; \" + list(meta_sub.agent2)[0] + \" \" + list(meta_sub.concentration2_chr)[0]\n",
    "            sns.kdeplot(logint, ax=ax, label = well + \" \" + trt, alpha=0.25, bw_adjust=smoothing).set_title(title)\n",
    "            ax.legend()\n",
    "        else:\n",
    "            sns.kdeplot(logint, ax=ax, alpha=0.25).set_title(title)\n",
    "        plt.close()\n",
    "    return(fig)\n",
    "\n",
    "def get_kde_plot_data_well(barcode, well,smoothing=1):\n",
    "    fig, ax = plt.subplots()\n",
    "    df = read_and_rename_well_data(barcode, well, silent = True)\n",
    "    ldrint = df['ldr'].copy()\n",
    "    ldrint[ldrint < 0] = float('nan')\n",
    "    logint = np.log10(ldrint)\n",
    "    x, y = sns.kdeplot(logint, ax=ax, color = \"grey\", alpha=0.5).get_lines()[0].get_data()\n",
    "    plt.close()\n",
    "    return(x,y)\n",
    "\n",
    "def get_logldrint(barcode, well):\n",
    "    df = read_and_rename_well_data(barcode, well, silent = True)\n",
    "    ldrint = df['ldr'].copy()\n",
    "    ldrint[ldrint < 0] = float('nan')\n",
    "    logint = np.log10(ldrint)\n",
    "    return(list(logint))\n",
    "\n",
    "def kde_plot_cell_line(barcode, cell_line, n_wells=None, well_start=0, title = \"\", add_legend=False, smoothing=1):\n",
    "    wells = get_wells(barcode, cell_line)\n",
    "    print(wells)\n",
    "    if n_wells is not None: wells = wells[well_start:(well_start+n_wells)]\n",
    "    if title == \"\": title = cell_line + \" \" + barcode\n",
    "    fig = kde_plot_wells(barcode, wells, title = title, add_legend=add_legend, smoothing=smoothing)\n",
    "    return(fig)\n",
    "\n",
    "def kde_plot_avg(barcode, cell_line, smoothing=1):\n",
    "    wells = get_wells(barcode, cell_line)\n",
    "    #if n_wells is not None: wells = wells[0:n_wells]\n",
    "    logint_all = []\n",
    "    #ax = axs[row,col]\n",
    "    fig, ax = plt.subplots()\n",
    "    for well in wells:\n",
    "        logint = get_logldrint(barcode, well)\n",
    "        logint_all.extend(logint)\n",
    "    #return(logint_all)\n",
    "    sns.kdeplot(logint_all, ax=ax, alpha=0.25, smoothing=smoothing).set_title(barcode + \" \" + cell_line)\n",
    "    plt.close()\n",
    "    return(fig)\n",
    "\n",
    "def kde_plot_all_avg(cell_line, n_barcodes=None, smoothing=1):\n",
    "    barcodes = get_all_plates_for_cell_line(cell_line)\n",
    "    fig, ax = plt.subplots()\n",
    "    if n_barcodes is not None: barcodes = barcodes[0:n_barcodes]\n",
    "    print(len(barcodes))\n",
    "    for i in range(len(barcodes)):\n",
    "        #print(i)\n",
    "        barcode = barcodes[i]\n",
    "        wells = get_wells(barcode, cell_line)\n",
    "        #if n_wells is not None: wells = wells[0:n_wells]\n",
    "        logint_all = []\n",
    "        for well in wells:\n",
    "            logint = get_logldrint(barcode, well)\n",
    "            logint_all.extend(logint)\n",
    "        #return(logint_all)\n",
    "        sns.kdeplot(logint_all, ax=ax, alpha=0.25, smoothing=smoothing).set_title(cell_line)\n",
    "        plt.close()\n",
    "    return(fig)\n",
    "\n",
    "def kde_plot_plate(barcode, n_wells = None, output_dir=\"\", filename=\"test_kde.pdf\",\n",
    "                   add_ldr_line=False, add_median_ldr_line=False, smoothing=1):\n",
    "    cell_lines = get_cell_lines_on_plate(barcode)\n",
    "    pdf_full = os.path.join(output_dir, filename)\n",
    "    nb_plots = len(cell_lines)\n",
    "    if nb_plots != 6: print(barcode + \": \" + str(nb_plots) + \" cell lines\")\n",
    "    if nb_plots == 0: return(None)\n",
    "    ncols = 2\n",
    "    nrows = int(np.ceil(nb_plots/2))\n",
    "    nrows = 3\n",
    "    fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(9, 4*nrows),\n",
    "                        layout=\"constrained\", sharex= \"all\")\n",
    "    ldr_cutoffs = []\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            i = row*ncols + col\n",
    "            if i == nb_plots: break\n",
    "            cell_line = cell_lines[i]\n",
    "            wells = get_wells(barcode, cell_line)\n",
    "            if n_wells is not None: wells = wells[0:n_wells]\n",
    "            logint_all = []\n",
    "            ax = axs[row,col]\n",
    "            for well in wells:\n",
    "                logint = get_logldrint(barcode, well)\n",
    "                logint_all.extend(logint)\n",
    "                sns.kdeplot(logint, ax=ax, alpha=0.25, smoothing=smoothing).set_title(cell_line)\n",
    "                ldr_gates, ldr_lims = dcf_int.get_ldrgates(np.array([10**x for x in logint]))\n",
    "                ldr_cutoff = ldr_gates[1]\n",
    "                ldr_cutoffs.append(ldr_cutoff)\n",
    "                if add_ldr_line:\n",
    "                    ax.axvline(ldr_cutoff,ymin=0, ymax=0.1, color = \"red\", linestyle = \"--\")\n",
    "            #sns.kdeplot(logint_all, ax=ax, color = \"red\").set_title(cell_line)\n",
    "            xmin = -2\n",
    "            xmax = 6\n",
    "            x_lims = (xmin, xmax)\n",
    "            plt.xlim(x_lims)\n",
    "            x_ticks = np.arange(np.ceil(xmin), np.floor(xmax)+1)\n",
    "            plt.xticks(x_ticks)\n",
    "            ax.tick_params(labelbottom=True)\n",
    "            if add_median_ldr_line:\n",
    "                med_cutoff = np.median(ldr_cutoffs)\n",
    "                #print(med_cutoff)\n",
    "                ax.axvline(x=med_cutoff, ymin=0, ymax=1, color = \"orange\")\n",
    "    fig.suptitle(barcode)\n",
    "    plt.savefig(pdf_full)\n",
    "    return(None)\n",
    "\n",
    "def kde_plot_all_plates(smoothing=1):\n",
    "    if not 'folder_dict' in globals(): define_folder_dict('folder_dict')\n",
    "    for date in folder_dict.keys():\n",
    "        print(date)\n",
    "        plates = get_barcodes(date)\n",
    "        plates.sort()\n",
    "        for plate in plates:\n",
    "            folder = \"density_plots\"\n",
    "            if not os.path.exists(folder): os.makedirs(folder)\n",
    "            file = plate + \".pdf\"\n",
    "            if os.path.exists(os.path.join(folder, file)):\n",
    "                print(plate)\n",
    "                print(\"pdf already written\")\n",
    "            else:\n",
    "                kde_plot_plate(plate, output_dir = folder, filename = file, smoothing=smoothing)\n",
    "                print(plate)\n",
    "    return(None)\n",
    "\n",
    "def kde_plot_all_plates_median(smoothing=1):\n",
    "    if not 'folder_dict' in globals(): define_folder_dict('folder_dict')\n",
    "    for date in folder_dict.keys():\n",
    "        print(date)\n",
    "        plates = get_barcodes(date)\n",
    "        plates.sort()\n",
    "        for plate in plates:\n",
    "            folder = \"density_plots_median_ldr\"\n",
    "            if not os.path.exists(folder): os.makedirs(folder)\n",
    "            file = plate + \"_median.pdf\"\n",
    "            if os.path.exists(os.path.join(folder, file)):\n",
    "                print(plate)\n",
    "                print(\"pdf already written\")\n",
    "            else:\n",
    "                kde_plot_plate(plate, output_dir = folder, filename = file, add_median_ldr_line=True, smoothing=smoothing)\n",
    "                print(plate)\n",
    "    return(None)\n",
    "\n",
    "def get_all_plates_for_cell_line(cell_line):\n",
    "    if not 'meta' in globals(): load_well_metadata('meta')\n",
    "    query = \"cell_line == '\"+cell_line+\"'\"\n",
    "    meta_sub = meta.query(query)\n",
    "    barcodes = meta_sub.barcode.unique()\n",
    "    return(barcodes)\n",
    "\n",
    "def kde_plot_all_plates_cell_line(cell_line, n_wells = None, n_barcodes=None, output_dir=\"\", \n",
    "                                  filename=\"test_kde_cell_line.pdf\", smoothing=1):\n",
    "    barcodes = get_all_plates_for_cell_line(cell_line)\n",
    "    barcodes.sort()\n",
    "    pdf_full = os.path.join(output_dir, filename)\n",
    "    ncols = 2\n",
    "    nrows = 3\n",
    "    pdf_pages = PdfPages(pdf_full)\n",
    "    fig_list = []\n",
    "    nb_plots = len(barcodes)\n",
    "    if n_barcodes is not None: nb_plots = n_barcodes\n",
    "    for i in range(nb_plots):\n",
    "        barcode = barcodes[i]\n",
    "        i_rel = (i % (ncols*nrows))\n",
    "        col = i_rel % ncols\n",
    "        row = i_rel // ncols\n",
    "        print(str(row) + \", \" + str(col))\n",
    "        if i % (ncols*nrows) == 0:\n",
    "            fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(9, 12),\n",
    "                        layout=\"constrained\", sharex= \"all\")\n",
    "            fig.suptitle(cell_line)\n",
    "        wells = get_wells(barcode, cell_line)\n",
    "        if n_wells is not None: wells = wells[0:n_wells]\n",
    "        ax = axs[row,col]\n",
    "        for well in wells:\n",
    "            logint = get_logldrint(barcode, well)\n",
    "            #logint_all.append(logint)\n",
    "            sns.kdeplot(logint, ax=ax, alpha=0.25, smoothing=smoothing).set_title(barcode)\n",
    "        #sns.kdeplot(logint_all, ax=ax, color = \"red\").set_title(cell_line)\n",
    "        xmin = -2\n",
    "        xmax = 6\n",
    "        x_lims = (xmin, xmax)\n",
    "        plt.xlim(x_lims)\n",
    "        x_ticks = np.arange(np.ceil(xmin), np.floor(xmax)+1)\n",
    "        plt.xticks(x_ticks)\n",
    "        ax.tick_params(labelbottom=True)\n",
    "        plt.close()\n",
    "        if (i + 1) % (ncols*nrows) == 0 or (i + 1) == nb_plots:\n",
    "            plt.tight_layout()\n",
    "            pdf_pages.savefig(fig)\n",
    "            plt.close('all')\n",
    "    pdf_pages.close()\n",
    "    return(None)\n",
    "\n",
    "def get_mixture_cutoff(model, n_iter=20, prob_tol=0.0001, update_tol=0.0001, silent=True):\n",
    "    mean1 = model.distributions[0].means.item()\n",
    "    mean2 = model.distributions[1].means.item()\n",
    "    #print(mean1)\n",
    "    #print(mean2)\n",
    "    min = np.min([mean1, mean2])\n",
    "    max = np.max([mean1, mean2])\n",
    "    prob = 0\n",
    "    cutoff = (min+max)/2\n",
    "    error = 0.5-prob\n",
    "    i=0\n",
    "    diff = 1\n",
    "    while (abs(error) > prob_tol or diff > update_tol) and i<n_iter:\n",
    "        i=i+1\n",
    "        if not silent:\n",
    "            print(i)\n",
    "            print(cutoff)\n",
    "        if i>1:\n",
    "            last_cutoff=cutoff\n",
    "        else:\n",
    "            last_cutoff=min\n",
    "        prob_both=model.predict_proba([[cutoff]])\n",
    "        prob1 = prob_both[0][0].item()\n",
    "        prob2 = prob_both[0][1].item()\n",
    "        if mean1<mean2:\n",
    "            prob=prob1\n",
    "        else:\n",
    "            prob=prob2\n",
    "        error = 0.5-prob\n",
    "        if prob>0.5:\n",
    "            min=cutoff\n",
    "        else:\n",
    "            max=cutoff\n",
    "        cutoff=(min+max)/2\n",
    "        diff=last_cutoff-cutoff\n",
    "        if not silent:\n",
    "            print(prob_both)\n",
    "            print(prob)\n",
    "    return(cutoff)\n",
    "\n",
    "### inputs: x,y from sns.kdeplot output\n",
    "def get_peaks_ldr(x, y, smoothing=1, first_peak_min=0.5,\n",
    "                 min_prominence=0, min_peak_height=0.02, min_peak_distance=1,\n",
    "                 single_peak_cutoff=3, silent=True):\n",
    "    x=x.copy()\n",
    "    y=y.copy()\n",
    "    peak_locs, peak_props = find_peaks(y.copy(), height=0, prominence=0)\n",
    "    peak_ldrs = x[peak_locs]\n",
    "    peak_props_orig=peak_props.copy()\n",
    "    peak_ldrs_orig=peak_ldrs.copy()\n",
    "    ### get rid of invalid peaks\n",
    "    keep_peaks = [peak_ldrs[i] > first_peak_min and \n",
    "                  peak_props['prominences'][i]>min_prominence and\n",
    "                 peak_props['peak_heights'][i]>min_peak_height for i in range(len(peak_ldrs))]\n",
    "    valid_peaks = np.sum(keep_peaks)\n",
    "    indexes = [i for i in range(len(keep_peaks)) if keep_peaks[i]]\n",
    "    peak_locs = [peak_locs[ind] for ind in indexes]\n",
    "    peak_ldrs = [peak_ldrs[ind] for ind in indexes]\n",
    "    for prop in peak_props:\n",
    "        peak_props[prop] = np.array([ peak_props[prop][ind] for ind in indexes ])\n",
    "    ### identify main peak and secondary peak\n",
    "    peak_order = np.argsort(-np.array(peak_props['peak_heights'])) ### in order of peak height\n",
    "    main_peak_index=peak_order[0]\n",
    "    secondary_peak_index = None\n",
    "    #### find the secondary peak\n",
    "    if len(peak_locs)>1:\n",
    "        ### loop over rest of peaks in order of height\n",
    "        for i in range(1,len(peak_locs)):\n",
    "            ### select next highest peak as long as it is sufficiently far from the first peak\n",
    "            if peak_ldrs[main_peak_index] < single_peak_cutoff:\n",
    "                check1 = peak_ldrs[peak_order[i]] - peak_ldrs[main_peak_index] > min_peak_distance\n",
    "            else:\n",
    "                check1 = peak_ldrs[main_peak_index] - peak_ldrs[peak_order[i]] > min_peak_distance\n",
    "            if check1:\n",
    "                secondary_peak_index = peak_order[i]\n",
    "                break\n",
    "                \n",
    "    if secondary_peak_index is None:\n",
    "        if not silent: print(\"search for shelf\")\n",
    "        ### search for a shelf if no secondary peak found\n",
    "        shelf_dict = find_shelf(x.copy(), y.copy(), main_peak_ldr=peak_ldrs[main_peak_index], \n",
    "                                min_peak_height=min_peak_height,first_peak_min=first_peak_min)\n",
    "        indexes = [main_peak_index]\n",
    "        peak_locs = [peak_locs[ind] for ind in indexes]\n",
    "        peak_ldrs = [peak_ldrs[ind] for ind in indexes]\n",
    "        for prop in peak_props:\n",
    "            peak_props[prop] = np.array([ peak_props[prop][ind] for ind in indexes ])\n",
    "        ### add shelf if found\n",
    "        if shelf_dict is not None:\n",
    "            shelf_ldr = shelf_dict['ldr']\n",
    "            shelf_height = shelf_dict['height']\n",
    "            if shelf_ldr < peak_ldrs[0]:\n",
    "                peak_ldrs = [shelf_ldr, peak_ldrs[0]]\n",
    "                shelf = \"peak1\"\n",
    "                peak_height1=shelf_height\n",
    "                peak_height2=peak_props['peak_heights'][0]\n",
    "            else:\n",
    "                peak_ldrs = [peak_ldrs[0], shelf_ldr]\n",
    "                shelf = \"peak2\"\n",
    "                peak_height1=peak_props['peak_heights'][0]\n",
    "                peak_height2=shelf_height\n",
    "        else: ### single peak case\n",
    "            shelf=\"none\"\n",
    "            if peak_ldrs[0]<single_peak_cutoff:\n",
    "                peak_height1=peak_props['peak_heights'][0]\n",
    "                peak_height2=float('nan')\n",
    "            else:\n",
    "                peak_height1=float('nan')\n",
    "                peak_height2=peak_props['peak_heights'][0]\n",
    "    else:\n",
    "        shelf=\"none\"\n",
    "        ### add peaks in order of their ldr intensity\n",
    "        if peak_ldrs[main_peak_index] < peak_ldrs[secondary_peak_index]:\n",
    "            indexes = [main_peak_index, secondary_peak_index]\n",
    "        else:\n",
    "            indexes = [secondary_peak_index, main_peak_index]\n",
    "        peak_locs = [peak_locs[ind] for ind in indexes]\n",
    "        peak_ldrs = [peak_ldrs[ind] for ind in indexes]\n",
    "        for prop in peak_props:\n",
    "            peak_props[prop] = np.array([ peak_props[prop][ind] for ind in indexes ])\n",
    "        peak_height1=peak_props['peak_heights'][0]\n",
    "        peak_height2=peak_props['peak_heights'][1]\n",
    "    if(len(peak_ldrs)==0):\n",
    "        print(\"Warning! No valid peaks\")\n",
    "        shelf=\"none\"\n",
    "        out={'peak1': float('nan'), 'peak2': float('nan'), 'peak1_height':float('nan'), 'peak2_height':float('nan'),\n",
    "             'shelf':shelf, 'peak_props':peak_props, 'peak_props_orig':peak_props_orig, 'peak_ldrs_orig': peak_ldrs_orig}\n",
    "    if(len(peak_ldrs)==1):\n",
    "        if(peak_ldrs[0] < single_peak_cutoff):\n",
    "            if not silent: print(\"only live cell peak found\")\n",
    "            out={'peak1': peak_ldrs[0], 'peak2': float('nan'), 'peak1_height':peak_height1, 'peak2_height':peak_height2,\n",
    "                 'shelf':shelf, 'peak_props':peak_props, 'peak_props_orig':peak_props_orig, 'peak_ldrs_orig': peak_ldrs_orig}\n",
    "        else:\n",
    "            if not silent: print(\"only dead cell peak found\")\n",
    "            out={'peak1': float('nan'), 'peak2': peak_ldrs[0],  'peak1_height':peak_height1, 'peak2_height':peak_height2,\n",
    "                 'shelf':shelf, 'peak_props':peak_props, 'peak_props_orig':peak_props_orig, 'peak_ldrs_orig': peak_ldrs_orig}\n",
    "    if(len(peak_ldrs)==2):\n",
    "        out={'peak1': peak_ldrs[0], 'peak2': peak_ldrs[1],  'peak1_height':peak_height1, 'peak2_height':peak_height2,\n",
    "             'shelf':shelf, 'peak_props':peak_props, 'peak_props_orig':peak_props_orig, 'peak_ldrs_orig': peak_ldrs_orig}\n",
    "    if(len(peak_ldrs)>2):\n",
    "        print(\"More than two peaks returned. This shouldn't happen -- must be a bug in the code\")\n",
    "        out={'peak1': peak_ldrs[0], 'peak2': peak_ldrs[1],  'peak1_height':peak_height1, 'peak2_height':peak_height2,\n",
    "             'shelf':shelf, 'peak_props':peak_props, 'peak_props_orig':peak_props_orig, 'peak_ldrs_orig': peak_ldrs_orig}\n",
    "    return(out)\n",
    "\n",
    "def get_ldr_cutoff_mixture(logint, peak_ldrs, show=True, mean_tol=0.4, silent=False):\n",
    "    #print(\"get_ldr_cutoff_mixture\")\n",
    "    logint = logint.copy()\n",
    "    peak_ldrs=peak_ldrs.copy()\n",
    "    ### mixture model\n",
    "    X = np.array(logint).reshape(-1,1)\n",
    "    X = torch.tensor(X).float()\n",
    "    try:\n",
    "        #print(\"model fitting\")\n",
    "        #print(peak_ldrs[0])\n",
    "        #print(peak_ldrs[1])\n",
    "        m1 = torch.tensor(peak_ldrs[0])\n",
    "        m2 = torch.tensor(peak_ldrs[1])\n",
    "        #m1.frozen=True\n",
    "        #m2.frozen=True\n",
    "        d1 = Normal(means=[m1], frozen = False)\n",
    "        d2 = Normal(means=[m2], frozen = False)\n",
    "        #d1.frozen=torch.tensor(True)\n",
    "        #d2.frozen=torch.tensor(True)\n",
    "        d3 = [d1,d2]\n",
    "        priors = np.empty((len(X), 2))\n",
    "        for i in range(len(priors)):\n",
    "            if X[i][0] < peak_ldrs[0]+0.5:\n",
    "                priors[i][0] = 1\n",
    "                priors[i][1] = 0\n",
    "            elif X[i][0] > peak_ldrs[1]-0.5:\n",
    "                priors[i][0] = 0\n",
    "                priors[i][1] = 1\n",
    "            else:\n",
    "                priors[i][0] = 0.5\n",
    "                priors[i][1] = 0.5\n",
    "        model = GeneralMixtureModel(d3, verbose=False, frozen=False, tol=0.001, max_iter=100, inertia=0.9).fit(X, priors=priors)\n",
    "    except:\n",
    "        if not silent: print(\"mixture model failed\")\n",
    "        return(float('nan'))\n",
    "    try:\n",
    "        ldr_cutoff = get_mixture_cutoff(model, silent=True)\n",
    "    except:\n",
    "        if not silent: print(\"get mixture cutoff failed\")\n",
    "        return(float('nan'))\n",
    "    if show:\n",
    "        try:\n",
    "            x = np.arange(np.min(logint), np.max(logint), 0.1)\n",
    "            y1 = model.distributions[0].probability(x.reshape(-1, 1))\n",
    "            y2 = model.distributions[1].probability(x.reshape(-1, 1))\n",
    "            y3 = model.probability(x.reshape(-1, 1))\n",
    "            #fig, ax = plt.subplots()\n",
    "            plt.figure(figsize=(6, 3))\n",
    "            plt.hist(X[:,0], density=True, bins=30)\n",
    "            plt.plot(x, y1, color = \"green\", label=\"Normal1\")\n",
    "            plt.axvline(peak_ldrs[0], color=\"green\", label=\"live peak\")\n",
    "            plt.plot(x, y2, color = \"red\", label=\"Normal2\")\n",
    "            plt.axvline(peak_ldrs[1], color=\"red\", label=\"dead peak\")\n",
    "            plt.plot(x, y3, color = \"purple\", label=\"Mixture\")\n",
    "            plt.axvline(ldr_cutoff, color=\"orange\", label=\"LDR cutoff\")\n",
    "            plt.legend(loc=(1.05, 0.4))\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except:\n",
    "            if not silent: print(\"plotting mixture model failed\")\n",
    "            return(float('nan'))\n",
    "    mean1 = model.distributions[0].means.item()\n",
    "    mean2 = model.distributions[1].means.item()\n",
    "    check1 = abs(mean1-peak_ldrs[0]) < mean_tol\n",
    "    check2 = abs(mean2-peak_ldrs[1]) < mean_tol\n",
    "    check3 = ldr_cutoff > peak_ldrs[0] and ldr_cutoff < peak_ldrs[1]\n",
    "    if(check1 and check2 and check3):\n",
    "        return(ldr_cutoff)\n",
    "    else:\n",
    "        if not silent: print(\"mixture model fitting failed\")\n",
    "        return(float('nan'))\n",
    "\n",
    "def get_ldr_cutoff_valley(x,y, peak_ldrs, silent=False):\n",
    "    x=x.copy()\n",
    "    y=y.copy()\n",
    "    peak_ldrs=peak_ldrs.copy()\n",
    "    ### find valley in between two most prominent peaks\n",
    "    x_sub = [val for val in x if val < peak_ldrs[1] and val > peak_ldrs[0] ]\n",
    "    y_sub = [val for val in y if val < peak_ldrs[1] and val > peak_ldrs[0] ]\n",
    "    y_sub_neg = [-val for val in y_sub]\n",
    "    valley_locs, valley_props = find_peaks(y_sub_neg, height=float('-Inf'), prominence=0)\n",
    "    if len(valley_locs) > 0:\n",
    "        ### get \"peak\" with maximum height -- all \"peaks\" will have negative height, so this will give the lowest valley\n",
    "        valley_ldrs = [ y_sub[loc] for loc in valley_locs ]\n",
    "        ldr_cutoff = np.max(valley_ldrs)\n",
    "        return(ldr_cutoff)\n",
    "    else:\n",
    "        if not silent: print(\"valley method failed\")\n",
    "        return(float('nan'))\n",
    "\n",
    "def get_ldrgates_new(ldrint, smoothing=1, show=True, first_peak_min=0.5,\n",
    "                     min_prominence=0, min_peak_height=0.02, min_peak_distance=0.5,\n",
    "                     single_peak_cutoff=3,\n",
    "                     mixture_backup_method=\"valley\", silent=True,\n",
    "                    return_peaks_only=False):\n",
    "    ldrint = ldrint[ldrint > 0]\n",
    "    logint = np.log10(ldrint)\n",
    "    logint = logint[ [not x for x in np.isnan(logint)] ]\n",
    "    logint = logint[ [not x for x in np.isinf(logint)] ]\n",
    "    logint = logint.copy()\n",
    "    if show:\n",
    "        fig, ax = plt.subplots()\n",
    "        x, y = sns.kdeplot(logint, ax=ax, bw_adjust=smoothing).get_lines()[0].get_data()\n",
    "        plt.close()\n",
    "    else:\n",
    "        x, y = sns.kdeplot(logint, bw_adjust=smoothing).get_lines()[0].get_data()\n",
    "        plt.close()\n",
    "    alive_dead_peaks = get_peaks_ldr(x.copy(), y.copy(), smoothing=smoothing, first_peak_min=first_peak_min,\n",
    "                                    min_prominence=min_prominence, min_peak_height=min_peak_height,\n",
    "                                    min_peak_distance=min_peak_distance, single_peak_cutoff=single_peak_cutoff,\n",
    "                                    silent=silent)\n",
    "    if return_peaks_only: return(alive_dead_peaks)\n",
    "    peak_ldrs = [alive_dead_peaks['peak1'], alive_dead_peaks['peak2']]\n",
    "    peak_ldrs = [x for x in peak_ldrs if not np.isnan(x)]\n",
    "    method_used=\"none\"\n",
    "    if show:\n",
    "        fig, ax = plt.subplots()\n",
    "        x, y = sns.kdeplot(logint, ax=ax, bw_adjust=smoothing).get_lines()[0].get_data()\n",
    "        #plt.show()\n",
    "    else:\n",
    "        x, y = sns.kdeplot(logint, bw_adjust=smoothing).get_lines()[0].get_data()\n",
    "        plt.close()\n",
    "    if len(peak_ldrs) == 1:\n",
    "        if not silent: print(\"one peak. almost all cells alive?\")\n",
    "        ### assume almost all cells are alive\n",
    "        if peak_ldrs[0] < single_peak_cutoff:\n",
    "            if not silent: print(\"one peak. almost all cells alive?\")\n",
    "            ldr_cutoff = np.quantile(logint, 0.99)\n",
    "            ldr_cutoff_mixture=ldr_cutoff\n",
    "            ldr_cutoff_valley=ldr_cutoff\n",
    "            ldr_cutoff_middle=ldr_cutoff\n",
    "        else:\n",
    "            if not silent: print(\"one peak. almost all cells dead?\")\n",
    "            ldr_cutoff = np.quantile(logint, 0.01)\n",
    "            ldr_cutoff_mixture=ldr_cutoff\n",
    "            ldr_cutoff_valley=ldr_cutoff\n",
    "            ldr_cutoff_middle=ldr_cutoff\n",
    "    elif len(peak_ldrs) > 1:\n",
    "        if return_peaks_only: return({'peak_ldrs':peak_ldrs, 'peak_props':peak_props})\n",
    "        ###### Note: write up this section as a new function: \"get_ldr_cutoff\"\n",
    "        ldr_cutoff_mixture = get_ldr_cutoff_mixture(logint.copy(), peak_ldrs, show=show, silent=silent)\n",
    "        ldr_cutoff_valley = get_ldr_cutoff_valley(x,y, peak_ldrs, silent=silent)\n",
    "        ldr_cutoff_middle = (peak_ldrs[0] + peak_ldrs[1])/2\n",
    "        if not np.isnan(ldr_cutoff_mixture):\n",
    "            method_used = \"mixture\"\n",
    "            ldr_cutoff = ldr_cutoff_mixture\n",
    "        elif not np.isnan(ldr_cutoff_valley):\n",
    "            method_used = \"valley\"\n",
    "            ldr_cutoff = ldr_cutoff_valley\n",
    "        else:\n",
    "            method_used = \"middle\"\n",
    "            ldr_cutoff = ldr_cutoff_middle\n",
    "    out = alive_dead_peaks\n",
    "    out['method_used'] = method_used\n",
    "    out['ldr_cutoff'] = ldr_cutoff\n",
    "    out['ldr_gates'] = np.array([-np.inf, ldr_cutoff])\n",
    "    out['ldr_cutoff_mixture'] = ldr_cutoff_mixture\n",
    "    out['ldr_cutoff_valley'] = ldr_cutoff_valley\n",
    "    out['ldr_cutoff_middle'] = ldr_cutoff_middle\n",
    "    #ldr_lims = np.array([x.min(), x.max()])\n",
    "    #return(ldr_gates, ldr_lims)\n",
    "    if not silent: print(out)\n",
    "    return(out)\n",
    "\n",
    "def get_ldrgates_new_well(barcode, well, smoothing=1.1, show=True, first_peak_min=0.5,\n",
    "                          min_prominence=0, min_peak_height=0.02, min_peak_distance=0.5,\n",
    "                          single_peak_cutoff=3,\n",
    "                          silent=True, return_peaks_only=False):\n",
    "    df = read_and_rename_well_data(barcode, well, silent=True)\n",
    "    ldrint = df['ldr'].copy()\n",
    "    results = get_ldrgates_new(ldrint, smoothing=smoothing, show=show, silent=silent,\n",
    "                               min_prominence=min_prominence, min_peak_height=min_peak_height,\n",
    "                               min_peak_distance=min_peak_distance, single_peak_cutoff=single_peak_cutoff,\n",
    "                               return_peaks_only=return_peaks_only)\n",
    "    return(results)\n",
    "\n",
    "\n",
    "def get_peaks_cell_line(barcode, cell_line, method=\"mixture\", smoothing=1, df_only=True, return_peaks_only=False):\n",
    "    wells = get_wells(barcode, cell_line)\n",
    "    peak_list=[]\n",
    "    df_list = []\n",
    "    for well in wells:\n",
    "        print(well)\n",
    "        pdict = get_ldrgates_new_well(barcode, well, show=True, return_peaks_only=return_peaks_only,\n",
    "                                      smoothing=smoothing, silent=True)\n",
    "        pdict['barcode']=barcode\n",
    "        pdict['cell_line']=cell_line\n",
    "        pdict['well']=well\n",
    "        if return_peaks_only:\n",
    "            cols = ['barcode', 'cell_line', 'well', 'peak1', 'peak2', \n",
    "                    'peak1_height', 'peak2_height','shelf']\n",
    "        else:\n",
    "            cols = ['barcode', 'cell_line', 'well', 'ldr_cutoff', 'peak1', 'peak2', \n",
    "                    'peak1_height', 'peak2_height','shelf','method_used', 'ldr_cutoff_mixture', 'ldr_cutoff_valley', 'ldr_cutoff_middle']\n",
    "        dd = {k:v for (k,v) in pdict.items() if k in cols}\n",
    "        df = pd.DataFrame(data=dd, index=[0])\n",
    "        df = df[cols]\n",
    "        df_list.append(df)\n",
    "        peak_list.append(pdict['peak_props'])\n",
    "    df_full = pd.concat(df_list)\n",
    "    df_full = df_full.reset_index()\n",
    "    if df_only:\n",
    "        return(df_full)\n",
    "    else:\n",
    "        ### return the peak lists later\n",
    "        return({'df':df_full, 'peak_props':peak_list})\n",
    "\n",
    "def get_peaks_barcode(barcodes, smoothing=1, df_only=True, return_peaks_only=False):\n",
    "    peak_list=[]\n",
    "    df_list = []\n",
    "    for barcode in barcodes:\n",
    "        cell_lines = get_cell_lines_on_plate(barcode)\n",
    "        for cell_line in cell_lines:\n",
    "            #print(cell_line)\n",
    "            wells = get_wells(barcode, cell_line)\n",
    "            for well in wells:\n",
    "                pdict = get_ldrgates_new_well(barcode, well, show=False, return_peaks_only=return_peaks_only,\n",
    "                                      smoothing=smoothing, silent=True)\n",
    "                pdict['barcode']=barcode\n",
    "                pdict['cell_line']=cell_line\n",
    "                pdict['well']=well\n",
    "                if return_peaks_only:\n",
    "                    cols = ['barcode', 'cell_line', 'well', 'peak1', 'peak2', \n",
    "                            'peak1_height', 'peak2_height','shelf']\n",
    "                else:\n",
    "                    cols = ['barcode', 'cell_line', 'well', 'ldr_cutoff', 'peak1', 'peak2', \n",
    "                            'peak1_height', 'peak2_height','shelf','method_used', 'ldr_cutoff_mixture', 'ldr_cutoff_valley', 'ldr_cutoff_middle']\n",
    "                dd = {k:v for (k,v) in pdict.items() if k in cols}\n",
    "                df = pd.DataFrame(data=dd, index=[0])\n",
    "                df = df[cols]\n",
    "                df_list.append(df)\n",
    "                peak_list.append(pdict['peak_props'])\n",
    "    df_full = pd.concat(df_list)\n",
    "    df_full = df_full.reset_index()\n",
    "    if df_only:\n",
    "        return(df_full)\n",
    "    else:\n",
    "        ### return the peak lists later\n",
    "        return({'df':df_full, 'peak_props':peak_list})\n",
    "\n",
    "def get_all_peaks(smoothing=1):\n",
    "    load_well_metadata('meta')\n",
    "    barcodes = meta['barcode'].unique()\n",
    "    out_file = \"peak_locations_new.csv\"\n",
    "    if os.path.exists(out_file):\n",
    "        df = pd.read_csv(out_file)\n",
    "        done_barcodes = list(df['barcode'])\n",
    "    barcodes = [bc for bc in barcodes if not (bc in done_barcodes)]\n",
    "    barcodes = sorted(barcodes)\n",
    "    for i in range(len(barcodes)):\n",
    "        barcode = barcodes[i]\n",
    "        print(barcode)\n",
    "        res = get_peaks_barcode([barcode], smoothing=smoothing)\n",
    "        if i==0 and not ('done_barcodes' in locals() or 'done_barcodes' in globals()):\n",
    "            res.drop(columns=['index']).to_csv(out_file, header=True, index=False)\n",
    "        else:\n",
    "            res.drop(columns=['index']).to_csv(out_file, mode='a', header=False, index=False)\n",
    "    return(res)\n",
    "\n",
    "## steps\n",
    "# 1) identify ends of left and right shelves\n",
    "# 2) if main peak < 3 (default) assume it's the live peak, otherwise assume it's the dead peak\n",
    "# 3) identify all x intervals that are:\n",
    "#        1) inbetween those two shelves\n",
    "#        2) at least min_distance=1 from first peak\n",
    "#        3) to the right of the peak (if main peak<3), or to the left of the peak  (if main peak < 3)\n",
    "# 4) identify the point closest to zero\n",
    "# 3) report the point as the second peak as long as it's close enough to 0\n",
    "\n",
    "### input x and y from the sns.kdeplot function\n",
    "def find_side_shelves(x, y, tol=0.03):\n",
    "    x = x.copy()\n",
    "    y = y.copy()\n",
    "    dx = np.diff(x)[0]\n",
    "    grad = np.gradient(y, dx)  ## first derivative\n",
    "    #grad2 = np.gradient(grad, dx)  ## second derivative\n",
    "    for i in range(len(grad)):\n",
    "        if abs(grad[i]) > tol:\n",
    "            end_left_shelf = x[i]\n",
    "            break\n",
    "    for i in reversed(range(len(grad))):\n",
    "        if abs(grad[i]) > tol:\n",
    "            end_right_shelf = x[i]\n",
    "            break\n",
    "    return({'end_left':end_left_shelf, 'end_right':end_right_shelf})\n",
    "\n",
    "def find_shelf_old(x, y, main_peak_ldr, min_peak_distance=1, single_peak_cutoff=3, tol=0.03):\n",
    "    sides = find_side_shelves(x,y,tol)\n",
    "    dx = np.diff(x)[0]\n",
    "    grad = np.gradient(y, dx)  ## first derivative\n",
    "    #grad2 = np.gradient(grad, dx)  ## second derivative\n",
    "    ### remove side shelves\n",
    "    ind = [list(x).index(val) for val in x if val > sides['end_left'] and val < sides['end_right']]\n",
    "    x = [x[i] for i in ind]\n",
    "    y = [y[i] for i in ind]\n",
    "    grad = [grad[i] for i in ind]\n",
    "    ### remove values close to the main peak (and to the wrong side of peak)\n",
    "    if main_peak_ldr < single_peak_cutoff: ## assume it's alive peak\n",
    "        ind = [list(x).index(val) for val in x if val > main_peak_ldr + min_peak_distance]\n",
    "        x = [x[i] for i in ind]\n",
    "        y = [y[i] for i in ind]\n",
    "        grad = [grad[i] for i in ind]\n",
    "    else: ### assume it's the dead peak\n",
    "        ind = [list(x).index(val) for val in x if val < main_peak_ldr - min_peak_distance]\n",
    "        x = [x[i] for i in ind]\n",
    "        y = [y[i] for i in ind]\n",
    "        grad = [grad[i] for i in ind]\n",
    "    ind_shelf = np.argmin(np.abs(grad))\n",
    "    #print(grad[ind_shelf])\n",
    "    if np.abs(grad[ind_shelf]) < tol:\n",
    "        #print('found')\n",
    "        return(x[ind_shelf])\n",
    "    else:\n",
    "        #print(\"not found\")\n",
    "        return(None)\n",
    "\n",
    "def find_shelf(x, y, main_peak_ldr, min_peak_distance=1, single_peak_cutoff=3, tol=0.03, \n",
    "               min_peak_height=0.02, first_peak_min=0.5, max_slope=0.3):\n",
    "    x = x.copy()\n",
    "    y = y.copy()\n",
    "    sides = find_side_shelves(x,y,tol)\n",
    "    dx = np.diff(x)[0]\n",
    "    grad = np.gradient(y, dx)  ## first derivative\n",
    "    #return(grad)\n",
    "    #grad2 = np.gradient(grad, dx)  ## second derivative\n",
    "    ### remove values close to the main peak (and to the wrong side of peak)\n",
    "    if main_peak_ldr < single_peak_cutoff: ## assume it's alive peak\n",
    "        #print('alive')\n",
    "        #print(main_peak_ldr + min_peak_distance)\n",
    "        #print(sides['end_right'])\n",
    "        ind = [list(x).index(val) for val in x if val > main_peak_ldr + min_peak_distance and val < sides['end_right']]\n",
    "        x = [x[i] for i in ind]\n",
    "        y = [y[i] for i in ind]\n",
    "        grad = [grad[i] for i in ind]\n",
    "        ### find peaks close to zero\n",
    "        peak_locs, peak_props = find_peaks(grad, height=float('-Inf'), prominence=0)\n",
    "    else: ### assume it's the dead peak\n",
    "        #print('dead')\n",
    "        #print(main_peak_ldr - min_peak_distance)\n",
    "        #print(sides['end_left'])\n",
    "        ind = [list(x).index(val) for val in x if val < main_peak_ldr - min_peak_distance and val > sides['end_left']]\n",
    "        x = [x[i] for i in ind]\n",
    "        y = [y[i] for i in ind]\n",
    "        grad = [grad[i] for i in ind]\n",
    "        neg_grad = [-x for x in grad]\n",
    "        ### find valleys close to zero\n",
    "        peak_locs, peak_props = find_peaks(neg_grad, height=float('-Inf'), prominence=0)\n",
    "    #return([x[i] for i in peak_locs])\n",
    "    if len(peak_locs)>0:\n",
    "        max_ind = np.argmin(abs(np.array(peak_props['peak_heights'])))\n",
    "        ### choose the peak with height closed to zero\n",
    "        shelf_loc = peak_locs[max_ind]\n",
    "        ldr_shelf = x[shelf_loc] ### return x coordinate (ldr intensity)\n",
    "        shelf_height = y[shelf_loc]\n",
    "        shelf_slope = grad[shelf_loc]\n",
    "        if ldr_shelf > first_peak_min and shelf_height>min_peak_height and abs(shelf_slope) < max_slope:\n",
    "            out = {'ldr':ldr_shelf, 'height':shelf_height, 'slope': shelf_slope}\n",
    "            #print(out)\n",
    "            return(out)\n",
    "        else:\n",
    "            return(None)\n",
    "    else:\n",
    "        return(None)\n",
    "\n",
    "def plot_density_derivative(barcode, well):\n",
    "    logint = get_logldrint(barcode, well)\n",
    "    fig, ax = plt.subplots()\n",
    "    x, y = sns.kdeplot(logint, ax=ax, bw_adjust=1).get_lines()[0].get_data()\n",
    "    plt.close()\n",
    "    #sides = find_side_shelves(x,y,tol)\n",
    "    dx = np.diff(x)[0]\n",
    "    grad = np.gradient(y, dx)  ## first derivative\n",
    "    gg1 = ggplot()+geom_line(aes(x=x, y=grad))\n",
    "    print(gg1)\n",
    "    out = {'x': x,'grad': grad}\n",
    "    neg_grad = [-x for x in grad]\n",
    "    peak_locs, peak_props = find_peaks(-grad, height=float('-Inf'), prominence=0)\n",
    "    out = {'peak_locs': peak_locs, 'peak_props': peak_props}\n",
    "    return(out)\n",
    "\n",
    "load_well_metadata('meta')\n",
    "define_regating_df('regate_df')\n",
    "define_folder_dict('folder_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a91e11a-5eda-4311-b071-594109e06ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_all_peaks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41743a26-fba5-4dbd-b536-855a653ec883",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['df_single']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf411f1-7f76-4439-a646-1c649c58931f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kde_plot_all_plates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c475c4-29ca-4b60-a4e7-e6b5bb121373",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plot_all_plates_median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394c5c9-3951-490f-8bc9-12f641f4bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plot_all_plates_cell_line(\"SUM185PE\", n_wells=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7135d589-2f15-4e45-9770-68c1d9cf324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"210406_combo_62\"\n",
    "#cell_line=\"HS578T\"\n",
    "well = \"D15\" ### detected w/o smoothing, shelf w/ smoothing=1.1\n",
    "well= \"C04\"\n",
    "#well = \"F21\"\n",
    "get_ldrgates_new_well(barcode, well, silent=False, smoothing=1)\n",
    "logint=get_logldrint(barcode, well)\n",
    "#kde_plot_wells(barcode, [well], smoothing=1)\n",
    "#test = get_peaks_cell_line(barcode, cell_line)\n",
    "#test1 = get_peaks_barcode([barcode], smoothing=1)\n",
    "#test2 = get_peaks_barcode([barcode], smoothing=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310973f1-51b4-4bda-bf25-fff7ca9f2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "logint = [x for x in logint if not math.isnan(x)]\n",
    "logint = sorted(logint)\n",
    "### x is the input sequence\n",
    "### n is the window size (window size of 2 is two on either side of reference value)\n",
    "def moving_sd(x,n):\n",
    "    sd_list=[]\n",
    "    i_list=[]\n",
    "    for i in range(n, len(x)-n):\n",
    "        vals=x[(i-n):(i+n+1)]\n",
    "        #print(vals)\n",
    "        sd = np.std(vals)\n",
    "        sd_list.append(sd)\n",
    "        i_list.append(i)\n",
    "    df=pd.DataFrame(data={'i':i_list,'sd':sd_list})\n",
    "    return(df)\n",
    "df=moving_sd(logint, 10)\n",
    "ggplot(df)+geom_point(aes(x='i',y='sd'))\n",
    "\n",
    "x1,y1 = get_kde_plot_data_well(barcode, well,smoothing=1)\n",
    "x,y=get_kde_plot_data_well(barcode, well,smoothing=1)\n",
    "dx = np.diff(x1)[0]\n",
    "grad = np.gradient(y1, dx)\n",
    "grad2 = np.gradient(grad, dx)\n",
    "gg1 =ggplot()+geom_line(aes(x=x1, y=y)) \n",
    "gg2 = ggplot()+geom_line(aes(x=x1, y=grad)) #+ coord_cartesian(ylim=[-0.05,0.05])\n",
    "#ggplot()+geom_point(aes(x=x1, y=grad2))\n",
    "print(gg1)\n",
    "print(gg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6284fc5-53ce-45fa-96b5-0a9d9268d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_shelf(x,y, main_peak_ldr=1,tol=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024c7b5-5b3c-4687-aa52-613037ebd92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"210406_combo_62\"\n",
    "#cell_line=\"HS578T\"\n",
    "well = \"D15\" ### detected w/o smoothing, shelf w/ smoothing=1.1\n",
    "#well= \"C04\"\n",
    "#well = \"F21\"\n",
    "barcode = \"210406_combo_71\"\n",
    "well = \"C06\"\n",
    "barcode=\"210806_combo_146\"\n",
    "well = \"E12\"\n",
    "\n",
    "get_ldrgates_new_well(barcode, well, smoothing=1, return_peaks_only=False, show=True, silent=False)\n",
    "plot_density_derivative(barcode, well)\n",
    "#test = get_ldrgates_new_well(barcode, well, smoothing=1, return_peaks_only=True, show=False, silent=True)\n",
    "#get_ldrgates_new_well(barcode, well, silent=False, smoothing=1, method = \"valley\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440475a7-640a-4898-8958-827a01462f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"210302_combo_61\"\n",
    "well = \"L09\"\n",
    "get_ldrgates_new_well(barcode, well, smoothing=1, return_peaks_only=False, show=True, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaff091-3720-44dd-83b5-1bb741ec830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode=\"201117_combo_19\"\n",
    "well=\"M06\"\n",
    "get_ldrgates_new_well(barcode, well, smoothing=1, method = \"mixture\", return_peaks_only=False, show=True, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e1f7d-b582-47ce-bc81-6aa97a094e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test2['df_double'].sort_values('peak2')\n",
    "df1 = pd.concat([test1['df_single'], test1['df_double']]).sort_values('well').reset_index()\n",
    "df2 = pd.concat([test2['df_single'], test2['df_double']]).sort_values('well').reset_index()\n",
    "df1['peak1_smooth'] = df2['peak1']\n",
    "df1['peak2_smooth'] = df2['peak2']\n",
    "df1 = df1.assign(peak1_diff = lambda x: x['peak1_smooth'] - x['peak1'],\n",
    "                peak2_diff = lambda x: x['peak2_smooth'] - x['peak2'])\n",
    "df_new = df1.query('peak2_smooth.isna() and peak2.notna()')\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f2205-88db-41fb-8274-3ca99db227a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1['df_single']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e2883-ea3d-45d0-903a-e27eedf42d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df1, aes(x='cell_line', y = 'peak2_diff')) + geom_boxplot() + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e2871-7db8-44d8-949a-5ccfb2c179b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode=\"210226_combo_51\"\n",
    "#well=\"K08\"\n",
    "well = \"K10\"\n",
    "#well = \"K15\"\n",
    "#plot_ldr_well(barcode=barcode, well=well)\n",
    "#get_ldrgates_new_well(barcode, well, smoothing=1, show=True, method=\"valley\")\n",
    "model = get_ldrgates_new_well(barcode, well, smoothing=1, show=True, method=\"mixture\", silent=True)\n",
    "test = get_ldrgates_new_well(barcode, well, show=False, return_peaks_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677b9e5-095e-427a-8a69-0338112502d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77362f-97b9-4c7c-ad79-deffaeb9bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode=\"210226_combo_51\"\n",
    "#well=\"K08\"\n",
    "well = \"K10\" ## most alive\n",
    "df_alive = read_and_rename_well_data(barcode, well)\n",
    "well = \"K15\" ## most dead\n",
    "df_dead = read_and_rename_well_data(barcode, well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c20fa15-06e1-4467-ae2a-3adf1dcfba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9284f054-8c6a-4ef1-980e-87caa58c5f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#barcode = \"201117_combo_19\"\n",
    "#cell_line = \"HCC70\"\n",
    "barcode = \"210406_combo_62\"\n",
    "cell_line=\"HS578T\"\n",
    "barcode=\"201117_combo_12\"\n",
    "cell_line=\"HCC1806\"\n",
    "cell_line=\"HCC1187\"\n",
    "barcode = '210406_combo_62'\n",
    "cell_line = 'SUM1315'\n",
    "barcode = '210423_combo_78'\n",
    "cell_line = 'SUM185PE'\n",
    "barcode=\"210406_combo_71\"\n",
    "cell_line=\"HS578T\"\n",
    "tmp = get_peaks_cell_line(barcode, cell_line)\n",
    "#tmp = get_peaks_barcode([barcode])\n",
    "#tmp_valley = get_peaks_cell_line(barcode, cell_line, method=\"valley\")\n",
    "#tmp = get_peaks_barcode(barcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca251694-7150-42df-aab4-1666c48a90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7840e6f-5abb-4a9a-8046-989bc47a81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_valley.iloc[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d2ce0-effc-4172-9a09-7d150bc82226",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp_orig.iloc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910a7af-0ace-4c5d-a983-1fd3858a3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"201117_combo_19\"\n",
    "cell_line = \"HCC70\"\n",
    "#tmp = get_peaks_cell_line(barcode, cell_line)\n",
    "tmp = get_peaks_barcode(barcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15a3c0-bfb2-46ce-adf4-9280a107291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp['df_double'].sort_values('peak2', ascending=False).iloc[1:10]\n",
    "tmp['df_single']\n",
    "#df_double_old = tmp['df_double']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869f7c3-7fe9-4d67-8588-ff96a6221597",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode='201117_combo_19'\n",
    "well='D12' ### misses second peak\n",
    "#well='C19' ### gets second peak w/o min_prominence argument\n",
    "#well='K13' ### tiny peak (prominence 0.015), but catches it\n",
    "#well='C05'\n",
    "#barcode='201117_combo_20'\n",
    "#well ='K19' ### very tiny peak (prominence 0.0102), but catches it\n",
    "#well = 'C03' ### misses second peak\n",
    "#well = 'C07'\n",
    "get_ldrgates_new_well(barcode, well, smoothing=1, show=True, method=\"mixture\", silent=False, \n",
    "                      min_prominence=0, min_peak_height=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181287f-d4f7-47a0-9237-87a1b3e25913",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(tmp['df_double'], aes(x='cell_line', y='peak1')) + geom_boxplot() + geom_jitter()\n",
    "#ggplot(tmp['df_single'], aes(x='cell_line', y='peak1')) + geom_boxplot() + geom_jitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879610a-22d8-423f-98eb-4faca7ac4bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_wells_ldr(barcode=\"211029_combo_185\", cell_line = \"SUM1315\")\n",
    "#kde_plot_plate(plate, output_dir = \"\", filename = file, add_median_ldr_line=True)\n",
    "kde_plot_cell_line(barcode=\"211029_combo_185\", cell_line = \"SUM1315\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd7c29-abc5-4682-a031-cb68b708a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_wells_ldr(barcode=\"211029_combo_185\", cell_line = \"HCC1395\")\n",
    "plot_wells_ldr(barcode=\"210226_combo_51\", cell_line = \"HCC38\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d185346c-74c4-4ba4-ae02-c670c3db52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"201117_combo_19\"\n",
    "cell_line = \"HCC70\"\n",
    "kde_plot_cell_line(barcode, cell_line)\n",
    "#plot_wells_ldr(barcode, cell_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a9a64f-5421-4da4-a454-7838a58d8326",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"211005_combo_161\"\n",
    "cell_line = \"SUM1315\"\n",
    "#plot_wells_ldr(barcode, cell_line)\n",
    "kde_plot_cell_line(barcode, cell_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279d6808-02e2-4db9-af4e-13d03e444d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"211005_combo_162\"\n",
    "cell_line = \"SUM149\"\n",
    "plot_wells_ldr(barcode, cell_line)\n",
    "kde_plot_cell_line(barcode, cell_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be17c247-9f82-44e3-ab9c-31f8a9edb267",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"201117_combo_28\"\n",
    "cell_line = \"SUM149\"\n",
    "kde_plot_cell_line(barcode, cell_line, n_wells=5, well_start=25, add_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f2b5bd-8cfe-4c1f-9733-41552ab24df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"201117_combo_13\"\n",
    "cell_line = \"HCC70\"\n",
    "kde_plot_cell_line(barcode, cell_line, n_wells=5, well_start=35, add_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0452761-684d-4111-9539-49691fac2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"201117_combo_32\"\n",
    "cell_line = \"HS578T\"\n",
    "kde_plot_cell_line(barcode, cell_line, n_wells=5, well_start=20, add_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75393333-0b16-4077-b9ff-8c804401e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"201117_combo_32\"\n",
    "well = \"C03\"\n",
    "plot_ldr_well(barcode, well)\n",
    "well = \"C05\"\n",
    "plot_ldr_well(barcode, well)\n",
    "meta_sub = get_well_meta(barcode, well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91294c62-6dac-47dd-980c-c81559e8c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(meta_sub.agent1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff6ea9-aef1-4f18-ab99-cae4c6de709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"201117_combo_13\"\n",
    "well = \"M05\"\n",
    "plot_ldr_well(barcode, well)\n",
    "well = \"M07\"\n",
    "plot_ldr_well(barcode, well)\n",
    "well = \"N14\"\n",
    "plot_ldr_well(barcode, well)\n",
    "test = \"dsafasfd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7849a56-3480-48e5-9719-aeff3646f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"201117_combo_28\"\n",
    "well = \"G06\"\n",
    "plot_ldr_well(barcode, well)\n",
    "well = \"G09\"\n",
    "plot_ldr_well(barcode, well)\n",
    "well = \"G08\"\n",
    "plot_ldr_well(barcode, well)\n",
    "well = \"G04\"\n",
    "plot_ldr_well(barcode, well)\n",
    "test = \"dsafasfd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75636c5e-8ee3-42dd-b76e-d9355ec8faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"201117_combo_32\"\n",
    "kde_plot_plate(barcode, n_wells=5, filename=\"test_lines.pdf\", add_median_ldr_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7068d253-2f37-4e16-9eea-f18d2af633a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(\"density_plots/201117_combo_12.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f6a46-88d8-424a-9c5b-584f8761c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plot_all_avg(cell_line, n_barcodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d3341-9814-4ebc-857c-8cd05dde4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line=\"SUM185PE\"\n",
    "#test = get_all_plates_for_cell_line(cell_line)\n",
    "kde_plot_all_avg(cell_line, n_barcodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c7166c-34d3-4288-bef3-1bdb85f002c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de9252-ca32-4e6f-9369-97c0e5e4a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"201117_combo_14\"\n",
    "wells = [\"C20\", \"D06\"]\n",
    "cell_line = \"HCC1187\"\n",
    "#kde_plot_wells(barcode, wells, title = \"testing\")\n",
    "#kde_plot_cell_line(barcode, cell_line, n_wells=3)\n",
    "\n",
    "barcode = \"210406_combo_62\"\n",
    "barcode = \"210423_combo_78\"\n",
    "kde_plot_plate(barcode, n_wells = 5, filename=\"test_new4.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f74ed1-32ac-4c0f-bb70-cbcc386e45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"201117_combo_14\"\n",
    "cell_line = \"HCC1187\"\n",
    "kde_plot_avg(barcode, cell_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34448c1a-d25a-44b9-99df-784231fee138",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = get_ldr_cutoffs_parallel()\n",
    "meta_ldr = meta\n",
    "meta_ldr['ldr_cutoff'] = cutoffs\n",
    "#meta_ldr.to_csv(\"meta_with_ldr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306a585-160a-44b4-b14d-9d3f42295bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### find possibly mis-gated wells\n",
    "df = pd.read_csv('meta_with_ldr.csv')\n",
    "df_tmp = df.query('cell_line == \"BT20\"')\n",
    "df_join = df.groupby(['cell_line', 'barcode']).agg({'ldr_cutoff': ['median', np.std]})\n",
    "df_join = df_join['ldr_cutoff']\n",
    "df_join['high_cutoff'] = df_join['median'] + 3*df_join['std']\n",
    "df_join['low_cutoff'] = df_join['median'] - 3*df_join['std']\n",
    "df2 = df.merge(df_join, on = ['cell_line', 'barcode'], how = 'left')\n",
    "df_high = df2.query('ldr_cutoff > high_cutoff')\n",
    "df_low = df2.query('ldr_cutoff < low_cutoff')\n",
    "df_high = df_high.reset_index()\n",
    "df_low = df_low.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65d7a5-392d-4027-a863-ea570b0c14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#barcode = \"211029_combo_180\"\n",
    "#cell_line = \"SUM1315\"\n",
    "#peak_loc = 1.2\n",
    "#well = \"G06\"\n",
    "\n",
    "bad_well_df = pd.read_csv(\"mis_gated.csv\")\n",
    "bad_well_df = bad_well_df.merge(df_high, on = ['barcode', 'well', 'cell_line'], how = 'left')\n",
    "bad_well_df\n",
    "i=4\n",
    "barcode = bad_well_df.barcode[i]\n",
    "cell_line = bad_well_df.cell_line[i]\n",
    "well = bad_well_df.well[i]\n",
    "med_ldr = bad_well_df['median'][i]\n",
    "df1 = get_counts_well(barcode, well, manual_ldr_cutoff=None, plot = True)\n",
    "print(df1)\n",
    "df2 = get_counts_well(barcode, well, manual_ldr_cutoff=3, plot = True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ccd794-0fb7-4702-a5fc-2edff64a50eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_low.iloc[50:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9150cfa-ab3d-44d9-8496-f06e600cea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = list(df_low.barcode)[53]\n",
    "cell_line = list(df_low.cell_line)[53]\n",
    "well = list(df_low.well)[53]\n",
    "print(barcode)\n",
    "print(cell_line)\n",
    "print(well)\n",
    "df_tmp = read_and_rename_well_data(barcode, well)\n",
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d7674-b9df-4f81-a02f-7814d4ef3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_high\n",
    "df = df_low\n",
    "#df.reset_index()\n",
    "#fig_list = []\n",
    "output_dir = \"\"\n",
    "#pdf = \"possible_misgated_high_3sigma.pdf\"\n",
    "pdf = \"possible_misgated_low_3sigma.pdf\"\n",
    "\n",
    "pdf_full = os.path.join(output_dir, pdf)\n",
    "pdf_pages = PdfPages(pdf_full)\n",
    "nb_plots = len(df.well)\n",
    "plots_per_page = 6\n",
    "#print(nb_plots)\n",
    "for i in range(nb_plots):\n",
    "    #print(i)\n",
    "    barcode = df.iloc[i].barcode\n",
    "    cell_line = df.iloc[i].cell_line\n",
    "    well = df.iloc[i].well\n",
    "    median_ldr = df.iloc[i]['median']\n",
    "    ldr_high = df.iloc[i].high_cutoff\n",
    "    agent1 = df.iloc[i].agent1\n",
    "    agent2 = df.iloc[i].agent2\n",
    "    conc1 = df.iloc[i].concentration1_chr\n",
    "    conc2 = df.iloc[i].concentration2_chr\n",
    "    fig_title = well + \" \" + barcode + \" \" + cell_line + \"\\n\" +str(agent1) + \" \" + str(conc1) + \" uM \" + str(agent2) + \" \" + str(conc2) + \" uM \" + \"\\n\" +\"Median LDR: \" + str(round(median_ldr, 2)) +\" LDR cutoff high: \" + str(round(ldr_high, 2))\n",
    "    if i % plots_per_page == 0:\n",
    "        fig = plt.figure(figsize=(8.5, 11))\n",
    "        outer = GridSpec(3, 2, wspace=0.2, hspace=0.5)\n",
    "    i_page = i % plots_per_page\n",
    "    ### make figures\n",
    "    try:\n",
    "        plot_ldr_well(barcode, well, add_ldr_line=median_ldr, fig=fig, outer=outer, i=i_page,\n",
    "                 silent=True, show_fig=False, scatter=True, title=fig_title)\n",
    "    except:\n",
    "        message = \"failed plotting: \" + well + \" \" + barcode + \" \" + cell_line\n",
    "        print(message)\n",
    "        \n",
    "    #fig_list.append(fig_tmp)\n",
    "    if (i + 1) % plots_per_page == 0 or (i + 1) == nb_plots:\n",
    "           plt.tight_layout()\n",
    "           pdf_pages.savefig()\n",
    "           plt.close('all')\n",
    "pdf_pages.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8c871-f6ae-4f40-a541-a81e2dbdd54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d707103-74b0-47a3-8b6e-6aa6afaec7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggplot(meta_ldr, aes(x = 'date', y = 'ldr_cutoff')) + geom_boxplot() + coord_flip() + facet_wrap('cell_line', scales = \"free_y\") +  theme(figure_size = (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66859f76-1fea-4e9d-bb28-074a6d069a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggplot(meta_ldr.query('cell_line == \"BT20\"'), aes(x = 'barcode', y = 'ldr_cutoff')) + geom_boxplot() + geom_jitter() + coord_flip() + theme(figure_size = (5, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564956ad-ae0c-46d4-bdd4-dcd9d995e67b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_all_problem_plates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6faf74-bbb5-4015-acc8-c86c7a70ea9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new_gating = regate_wells()\n",
    "df_new_gating.to_csv('regating_counts_07_10_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359d998-5a51-4ed8-a059-f094639a82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = get_ldr_cutoffs_plate(\"211029_combo_180\", peak_loc = 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca8e6a-6655-429c-8dd8-a0a871acc8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df1, aes(x = 'cell_line', y = 'ldr_cutoff')) + geom_boxplot() + geom_jitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079396ee-829f-4e43-ab15-5bbddc0f0fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"211029_combo_180\"\n",
    "cell_line = \"SUM1315\"\n",
    "well = \"G06\"\n",
    "#plot_wells_ldr(barcode, cell_line, output_dir = \"\")\n",
    "#plot_ldr_well(barcode, well)\n",
    "\n",
    "######## plot peaks w/ normal algorithm\n",
    "df = read_and_rename_well_data(barcode, well, silent=True)\n",
    "ldrint = df['ldr']\n",
    "ldrint = ldrint[ldrint > 0]\n",
    "logint = np.log10(ldrint)\n",
    "\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "x, y = sns.kdeplot(logint, ax=ax).get_lines()[0].get_data()\n",
    "\n",
    "peak_locs, _ = find_peaks(-y)\n",
    "#print(peak_locs)\n",
    "cc = x[peak_locs]\n",
    "print(cc)\n",
    "\n",
    "###### plot peaks w/ negative ldr values mapped to minimum positive ldr\n",
    "df = read_and_rename_well_data(barcode, well, silent=True)\n",
    "\n",
    "df_pos1 = df.query(\"ldr > 0\")\n",
    "min_ldr = np.min(df_pos1.ldr)\n",
    "df_pos2 = df.query(\"dna > 0\")\n",
    "min_dna = np.min(df_pos2.dna)\n",
    "df['ldr'] = [x if x>0 else min_ldr for x in df.ldr]\n",
    "df['dna'] = [x if x>0 else min_dna for x in df.dna]\n",
    "\n",
    "ldrint = df['ldr']\n",
    "ldrint = ldrint[ldrint > 0]\n",
    "logint = np.log10(ldrint)\n",
    "\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "x, y = sns.kdeplot(logint, ax=ax).get_lines()[0].get_data()\n",
    "\n",
    "peak_locs, _ = find_peaks(-y)\n",
    "#print(peak_locs)\n",
    "cc = x[peak_locs]\n",
    "print(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3201ec4-d26c-4535-b140-fd3f635e4988",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"211029_combo_180\"\n",
    "cell_line = \"SUM1315\"\n",
    "peak_loc = 1.2\n",
    "well = \"G06\"\n",
    "well = \"C19\"\n",
    "well = \"C20\"\n",
    "\n",
    "\n",
    "######## plot peaks w/ smoothing\n",
    "df = read_and_rename_well_data(barcode, well, silent=True)\n",
    "ldrint = df['ldr']\n",
    "ldrint = ldrint[ldrint > 0]\n",
    "logint = np.log10(ldrint)\n",
    "\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "x, y = sns.kdeplot(logint, ax=ax, bw_adjust=1).get_lines()[0].get_data()\n",
    "peak_locs, test = find_peaks(-y, prominence=0, width=0)\n",
    "#print(peak_locs)\n",
    "cc = x[peak_locs]\n",
    "try:\n",
    "    ldr_cutoff = cc[cc > peak_loc][0]\n",
    "except IndexError:\n",
    "    ldr_cutoff = np.quantile(logint, 0.99)\n",
    "plt.axvline(x=ldr_cutoff, ls = \"--\", color = \"red\")\n",
    "print(cc)\n",
    "print(test)\n",
    "print(ldr_cutoff)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x, y = sns.kdeplot(logint, ax=ax, bw_adjust=1.5).get_lines()[0].get_data()\n",
    "peak_locs, test = find_peaks(-y, prominence=0, width=0)\n",
    "#print(peak_locs)\n",
    "cc = x[peak_locs]\n",
    "try:\n",
    "    ldr_cutoff = cc[cc > peak_loc][0]\n",
    "except IndexError:\n",
    "    ldr_cutoff = np.quantile(logint, 0.99)\n",
    "plt.axvline(x=ldr_cutoff, ls = \"--\", color = \"red\")\n",
    "print(cc)\n",
    "print(test)\n",
    "print(ldr_cutoff)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x, y = sns.kdeplot(logint, ax=ax, bw_adjust=2).get_lines()[0].get_data()\n",
    "peak_locs, test = find_peaks(-y, prominence=0, width=0)\n",
    "#print(peak_locs)\n",
    "cc = x[peak_locs]\n",
    "try:\n",
    "    ldr_cutoff = cc[cc > peak_loc][0]\n",
    "except IndexError:\n",
    "    ldr_cutoff = np.quantile(logint, 0.99)\n",
    "plt.axvline(x=ldr_cutoff, ls = \"--\", color = \"red\")\n",
    "print(cc)\n",
    "print(test)\n",
    "print(ldr_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da86c6a-065b-4693-9358-9e2ce1c7075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"211029_combo_180\"\n",
    "cell_line = \"SUM1315\"\n",
    "peak_loc = 1.2\n",
    "well = \"C19\"\n",
    "df_test = read_and_rename_well_data(barcode, well)\n",
    "test = plot_ldr(df_test, peak_loc = peak_loc)\n",
    "dcf_int.get_counts_df(df=df_test, barcode=barcode, well=well, peak_loc = peak_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bebf64a-d0b6-4292-9725-ee860ada055c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "barcode = \"211029_combo_180\"\n",
    "cell_line = \"SUM1315\"\n",
    "well = \"G06\"\n",
    "\n",
    "###### plot peaks w/ negative ldr values mapped to minimum positive ldr\n",
    "df = read_and_rename_well_data(barcode, well, silent=True)\n",
    "\n",
    "df_pos1 = df.query(\"ldr > 0\")\n",
    "min_ldr = np.min(df_pos1.ldr)\n",
    "df_pos2 = df.query(\"dna > 0\")\n",
    "min_dna = np.min(df_pos2.dna)\n",
    "df['ldr'] = [x if x>0 else min_ldr for x in df.ldr]\n",
    "df['dna'] = [x if x>0 else min_dna for x in df.dna]\n",
    "\n",
    "ldrint = df['ldr']\n",
    "ldrint = ldrint[ldrint > 0]\n",
    "logint = np.log10(ldrint)\n",
    "\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "x, y = sns.kdeplot(logint, ax=ax).get_lines()[0].get_data()\n",
    "\n",
    "peak_locs, _ = find_peaks(-y, prominence=0.2)\n",
    "#print(peak_locs)\n",
    "cc = x[peak_locs]\n",
    "print(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37c085-1838-4fc5-b2c6-7015115d4054",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = \"211029_combo_180\"\n",
    "well = \"G06\" ### example of bad gating\n",
    "well = \"C07\" ### example of good separation, large peak\n",
    "\n",
    "######## plot peaks w/ peak_prominence\n",
    "df = read_and_rename_well_data(barcode, well, silent=True)\n",
    "ldrint = df['ldr']\n",
    "ldrint = ldrint[ldrint > 0]\n",
    "logint = np.log10(ldrint)\n",
    "\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "x, y = sns.kdeplot(logint, ax=ax).get_lines()[0].get_data()\n",
    "\n",
    "peak_locs, test = find_peaks(-y, prominence=0.1, width = 30)\n",
    "#print(peak_locs)\n",
    "cc = x[peak_locs]\n",
    "print(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8193123a-0955-476f-a4a2-57ab6b94e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952dc93-342e-4522-83ea-67eb5e08392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## plot peaks w/ normal algorithm\n",
    "df = read_and_rename_well_data(barcode, well, silent=True)\n",
    "ldrint = df['ldr']\n",
    "ldrint = ldrint[ldrint > 0]\n",
    "logint = np.log10(ldrint)\n",
    "\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "x, y = sns.kdeplot(logint, ax=ax).get_lines()[0].get_data()\n",
    "\n",
    "peak_locs, _ = find_peaks(-y)\n",
    "#print(peak_locs)\n",
    "cc = x[peak_locs]\n",
    "print(cc)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "# plot the data\n",
    "ax.plot(x,-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0d21f-6a7d-438f-b9c9-a7864623378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### test viewing a few plates, looking for badly gated wells\n",
    "barcode = \"211029_combo_180\"\n",
    "cell_line = \"BT20\"\n",
    "#plot_wells_ldr(barcode, cell_line, output_dir = \"\")\n",
    "\n",
    "barcode = \"211029_combo_182\"\n",
    "cell_line = \"SUM159\"\n",
    "#plot_wells_ldr(barcode, cell_line, output_dir = \"\")\n",
    "\n",
    "\n",
    "barcode = \"211029_combo_180\"\n",
    "cell_line = \"SUM1315\"\n",
    "plot_wells_ldr(barcode, cell_line, output_dir = \"\")\n",
    "\n",
    "#well = \"D12\"\n",
    "#plot_ldr_well(barcode, well)\n",
    "#df = read_and_rename_well_data(barcode, well)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf2483-2468-4284-b66f-bf083a8ff893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9b583c-ae1f-40f1-94cc-19d9c0ac4f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c60739-4579-4314-a4e0-03c9c904231a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04bcf17-2379-4d11-b4e4-8a148b612ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60579659-ce05-4de6-9a7c-55e7d64564e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    if df.ldr[i]<=0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024f21e-608f-4989-ba66-22eb1e32ffb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845bc69-d951-4274-a121-7ef1f8a1a4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088505c-17bf-450c-beff-9dbe9db0b447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f314c-c681-4f8a-89f5-e11b1631f341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7b6ea-dc67-4069-9e28-28fcfda9ccbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588f8a06-2c55-4135-b90d-cf9f5e58d995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936dec50-9c87-4063-9658-34613f4e3b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d8bcd-3bc3-4a1d-b7b3-b0e17df0aa51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a35ea7-e1ce-4292-a416-22e1b1f2a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta_sub = meta.filter(meta.columns[0:9])\n",
    "#df_new = df_new_gating.merge(meta_sub, on = ['barcode', 'well'], how = 'left')\n",
    "#df_new.sort_values(by=['cell_count__dead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0107969-f5e2-4975-a90c-aa570f4a2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new.query('agent1 == \"\"').sort_values(by=['cell_count__dead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81599fdf-75f1-457f-9267-6a10b0bd527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#barcode = '210226_combo_51'\n",
    "#cell_line = 'HCC1937'\n",
    "#well = \"I06\"\n",
    "#well = \"J07\"\n",
    "\n",
    "#barcode = '210226_combo_52'\n",
    "#cell_line = 'HCC1937'\n",
    "#well = \"I11\"\n",
    "\n",
    "#barcode = '210226_combo_53'\n",
    "#cell_line = 'HCC1937'\n",
    "#well = \"I18\"\n",
    "\n",
    "barcode = '210226_combo_54'\n",
    "cell_line = 'HCC1937'\n",
    "well = \"I03\"\n",
    "well = \"I11\"\n",
    "well = \"J04\"\n",
    "well = \"J07\"\n",
    "\n",
    "barcode = '210226_combo_55'\n",
    "cell_line = 'HCC1937'\n",
    "well = \"I15\"\n",
    "\n",
    "barcode = '210226_combo_56'\n",
    "cell_line = 'HCC1937'\n",
    "well = \"I11\"\n",
    "#well = \"I14\"\n",
    "#well = \"I18\"\n",
    "#well = \"I21\"\n",
    "\n",
    "barcode = '210226_combo_57'\n",
    "cell_line = 'HCC1937'\n",
    "well = \"I03\"\n",
    "well = \"I06\"\n",
    "well = \"I11\"\n",
    "well = \"J04\"\n",
    "well = \"J07\"\n",
    "\n",
    "barcode = '210302_combo_59'\n",
    "cell_line = 'HCC1937'\n",
    "well = \"I15\"\n",
    "#well = \"J20\"\n",
    "\n",
    "barcode = '210302_combo_60'\n",
    "cell_line = 'HCC1937'\n",
    "well = \"I11\"\n",
    "well = \"I18\"\n",
    "\n",
    "barcode = '210302_combo_61'\n",
    "cell_line = 'HCC1937'\n",
    "well = \"I06\"\n",
    "#well = \"J07\"\n",
    "\n",
    "barcode = '210406_combo_69'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"E15\"\n",
    "well = \"F20\"\n",
    "\n",
    "barcode = '210406_combo_70'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"E18\"\n",
    "#well = \"E11\"\n",
    "\n",
    "barcode = '210406_combo_71'\n",
    "cell_line = 'SUM1315'\n",
    "#well = \"E06\"\n",
    "well = \"F07\"\n",
    "\n",
    "barcode = '210406_combo_72'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"E11\"\n",
    "#well = \"E12\"\n",
    "#well = \"E14\"\n",
    "#well = \"E15\"\n",
    "#well = \"F20\"\n",
    "\n",
    "barcode = '210406_combo_73'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"E11\"\n",
    "#well = \"E14\"\n",
    "#well = \"E18\"\n",
    "#well = \"E21\"\n",
    "#well = \"F05\"\n",
    "\n",
    "barcode = '210406_combo_74'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"E03\"\n",
    "well = \"E06\"\n",
    "well = \"E11\"\n",
    "well = \"F04\"\n",
    "well = \"F07\"\n",
    "\n",
    "barcode = '210406_combo_75'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"E11\"\n",
    "#well = \"E12\"\n",
    "#well = \"E14\"\n",
    "#well = \"E15\"\n",
    "#well = \"F20\"\n",
    "\n",
    "barcode = '210406_combo_76'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"E11\"\n",
    "well = \"E14\"\n",
    "well = \"E18\"\n",
    "well = \"E21\"\n",
    "well = \"F05\"\n",
    "\n",
    "barcode = '210406_combo_77'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"E03\"\n",
    "#well = \"E06\"\n",
    "#well = \"E11\"\n",
    "#well = \"F04\"\n",
    "#well = \"F07\"\n",
    "\n",
    "barcode = '211005_combo_158'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"G11\"\n",
    "well = \"G12\"\n",
    "well = \"G14\"\n",
    "\n",
    "barcode = '211005_combo_160'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"G11\"\n",
    "well = \"G12\"\n",
    "well = \"G14\"\n",
    "\n",
    "barcode = '211005_combo_164'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"G11\"\n",
    "#well = \"G14\"\n",
    "#well = \"H20\"\n",
    "\n",
    "barcode = '211005_combo_165'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"G11\"\n",
    "#well = \"G14\"\n",
    "#well = \"H20\"\n",
    "\n",
    "barcode = '211005_combo_166'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"G11\"\n",
    "well = \"H04\"\n",
    "well = \"H07\"\n",
    "\n",
    "### using DNAcontent column as dna -- same as before\n",
    "df_test = read_and_rename_well_data(barcode, well)\n",
    "### using HoechstINT column as dna\n",
    "### note: using Hoechst gives lower dead count -- only 12 dead_subg1 vs. ~500 for DNAContent\n",
    "#df_test = read_and_rename_well_data(barcode, well, hoechst_as_dna=True)\n",
    "peak_loc = 1.2\n",
    "test = plot_ldr(df_test, peak_loc = peak_loc)\n",
    "dcf_int.get_counts_df(df=df_test, barcode=barcode, well=well, peak_loc = peak_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92013f60-623d-4eb5-95e5-aa95d1d4f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing wells that legitimately do have high dead counts\n",
    "\n",
    "barcode = \"210423_combo_84\"\n",
    "well = \"K21\" ### Alp. + Tram -- cutoff at 1.5 ?? -- similar for K19\n",
    "well = \"K11\" ### ctrl well -- low dead cells -- cutoff at ~3.25\n",
    "\n",
    "### using DNAcontent column as dna -- same as before\n",
    "df_test = read_and_rename_well_data(barcode, well)\n",
    "### using HoechstINT column as dna\n",
    "### note: using Hoechst gives lower dead count -- only 12 dead_subg1 vs. ~500 for DNAContent\n",
    "#df_test = read_and_rename_well_data(barcode, well, hoechst_as_dna=True)\n",
    "peak_loc = 1.2\n",
    "test = plot_ldr(df_test, peak_loc = peak_loc)\n",
    "dcf_int.get_counts_df(df=df_test, barcode=barcode, well=well, peak_loc = peak_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c1c393-ff12-4916-a719-52eeaa5787fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3435f92-38aa-4818-a050-0c8c2d871583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69487c1-fa30-4959-97f9-14dbf63d6e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95345a4d-1d97-42ed-9b96-1a0e9bc33989",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode = '210406_combo_62'\n",
    "cell_line = 'SUM1315'\n",
    "well = \"E03\"\n",
    "\n",
    "#barcode = \"210423_combo_78\"\n",
    "#well = 'K04'\n",
    "#cell_line = \"SUM185PE\"\n",
    "\n",
    "#test = plot_problem_plate(barcode, cell_line)\n",
    "plot_ldr_well(barcode, well, peak_loc = 1.2)\n",
    "df_test = read_and_rename_well_data(barcode, well)\n",
    "df_tmp = dcf_int.get_counts_df(df=df_test, barcode=barcode, well=well, peak_loc = 1.2)\n",
    "#plot_wells_ldr(barcode, cell_line)\n",
    "#df_tmp\n",
    "\n",
    "dcf_int.get_ldrgates(df_test.ldr, peak_loc=1.2)[0]\n",
    "#df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79008100-e9e0-4c37-9b7b-ec03bbb145a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
